Everybody knows what file is, right? Everybody's been using files, at least on their user level, so this should be pretty simple. But from the perspective of the operating system, file is just an abstraction that holds a stream of bytes. So basically a file is a sequence of bytes. That's it. Operating system has no other, no further knowledge of what file is. It just stores chunk of data. And this abstraction is used for other applications to store the data usually in a secondary storage. So usually in a persistent way, which, so the file will survive the power outage, the file will survive the reboot of the computer, etcetera. And also the file can be used to exchange data on more, let's say on longer distances, on more via more elaborate communicating channels, etcetera. Most importantly, file provides a sort of identification and and then again, there is some semantic gap between what you know of files because you identify files via their names and usually via their location within some folders. But the system uses some numeric identifiers. So the operating system for for the operating system, the file is basically a number, OK. And this number is translated actually vice versa name and path which is something you are used to as a users is translated to this number via some via some mechanisms of the file systems. So this way both sides are happy because for humans we still have mnemonic way how to identify the files. Because if you name the file funny video dot MP4 or something, then you know it's a funny video right? Right away. You can identify it, you can remember it. If you identify the file by a huge number, you as a humans wouldn't identify it. And there are, unless there are some cyborgs amongst you. So for the humans, we are happy. And for the operating systems, the operating system is still happy because numbers are much more easier to handle, much more easier to store, much more easier to process. Yeah, some parts of the file name sometimes have special meaning. Again, this is not usually the thing of the core of the operating system. This is not the kernel stuff. But some parts of the operating system like the libraries, like the extensions, like the user environment, which is sometimes integrated or more or less integrated. Part of an operating system can interpret certain file names with certain meaning. For instance, Windows tend to interpret extensions of the files like exa.com dot text or something with certain meaning. For instance, if you have a file with Exa extension, the Windows environment will guess it's probably an application and it can be executed. So it will offer you a way how to run this file as if it was a program. So it suspects it contains the instructions and all the other data of an application, and it tries to load and execute this file as if it was a program if it contains another extension. Some of these extensions are listed somewhere in the registry of the files of the operating system and it uses specific applications. You open TXT file, it will open your favorite text, browser, text editor. If you open JPEG file, it will open some image browser, et cetera. OK, so this was like fundamentals to get everyone on the same ground. Not too much information there. What you should already know, or what you probably seen at these glimpses of, is how the file is handled or how files are handled in programs in your code. So this is AC code using the standard library in C Very low level stuff. How to open and read a file. So basically you need to open the file 1st and that this is the place where the translation between the path between the mnemonic representation that is common to humans is translated to some numeric representation. Actually, not completely, not exactly. In this abstraction we are getting some pointer, so the details are hidden within some C structure and we are getting pointers to this structure. So it's even more elaborate than that. But that's not that important. We are getting some sort of handle. This FP is like a handle. We can use it only to be passed into very specific functions that operate files. OK and I can test it. If I get a new pointer then I know this file wasn't open. Actually it was. There was some error when I was trying to open the file. For instance, the file doesn't exist. That's a common mistake because I got the name wrong or somebody have deleted it since or I don't have permissions to read this file for instance. So something happens, something bad happens and this file wasn't open. So I'm checking whether I get the valid handle or not. OK, by the way these are over here just a crude way how to tell this abstraction that I would like to read the file. There can be W for write if I want to write the file and also there are some other acronyms like a for appending etcetera. So this string somehow represents the mode in which I would like to access the file. And once I pass this, so if I open the file successfully, then I can perform various tasks. For instance, I can see the file. By the way, this abstraction allows me to, let's say, have some secret hidden pointer within this file. If I open it for reading, this pointer points to the beginning of the file because it expects that I tried to read the file from the beginning to the end. If I open it for appending, this pointer will be at the end. So I can start writing at the end of the file. So I can move this pointer, I can I can adjust it as I wish using the seek operation. So by seeking, I will move this internal hidden pointer which is embedded somewhere within this or associated somewhere with this, with this handler to position 42. And this, this mysterious anum, this mysterious constant will tell this function that I'm seeking it from the beginning of the file. So this is like an absolute address, absolute value. Yeah, I can move it relatively or from the end or something not that important. This is just an adjustment of the internal pointer from which this following read operation will start. And this is getting some characters, in this case characters because I've opened it as a text file, but it can also be some buffer of bytes. I can read binary files as well this way. So this is the pointer to a buffer. This is allocated memory. And I'm reading 16 bytes from this file pointer. Easy enough. And finally, when I'm done, I've read what I wanted, I need to close the file. Well, I don't have to, because when my process terminates, the operating system automatically closes all the files this process was holding. So this is not like a mandatory operation. If your application terminates over here, then it's like a maybe slightly redundant, redundant line. But in the end, it's always good practice to be tidy and to clean up your own mess. So it's a good practice to close your own files once you've opened them. So this is like the last one. And after this I won't be able to use this pointer, this this handler anymore. This is analogy which is written using POSIX abstraction. You probably heard about POSIX in the Linux class. That's right. The POSIX is is like a API specification for Unix operating systems. So if you want to use a very low level Unix stuff, then you can use POSIX directly. Basically libc is implemented on the top of POSIX if you're in the Linux files or in Unix environment. Libc is built on top of Windows functions, which are similar, but they have somewhat more awkward names, longer names, but very similar API. So it's implemented over a different API, but in a very similar manner if you're in the Windows environment. So this is like a benefit that the libc is providing to us is a portability. I can write the same code for Windows, for Unix, for technically, possibly for other operating systems as well. So as you can see, these lines are translated almost one to one, in this case 1:00 to 1:00, because when I'm opening the file using the libc abstraction, there is an analogical function open in POSIX and as you can see, it gets similar arguments. Again, it gets the path to the file and also it gets some flags which indicate what I'm going to do with the file. There is only slight discrepancy here. I'm providing it using some awkward string which is defined in libc library. Here there is a set of constants, set of numbers. Actually this is like a macro constant which is provided by the header which I can put here to tell the operating systems. I would like to only read this file, and again, I need to check whether the descriptor here is valid. By the way, the descriptor over here is a number, is an integer. Here is some more mysterious black box structure, and I'm getting a pointer to that, but here it's a normal number. And by the way, you need to know the specification. Yeah, POSIX is somewhat clumsy in this way, because sometimes you need to know. Everybody knows right That if you get a negative number, actually if you get a -, 1, it's an error. Positive numbers are fine, negative numbers are errors. So -1 in this case is. In this case -1 is the only one only number that can be returned. So if -1 is returned as the handler, I know it's invalid handler. I shouldn't use it for operations. I need to handle the error in the same manner like I handled it in over here. And later you can see the the functions are named slightly differently, but basic. Yeah, the order of the arguments is slightly different, but basically it's the same stuff. You just need to look up this in the manuals. So you you proper properly use the proper function with the proper order of the arguments, but it's the same stuff. What's slightly different? Sorry, Yeah, you get it on another file. What's slightly different is that this number is a number, and I can interpret it as such. And this number is actually sequentially assigned. You've already witnessed that when I was showing you the stack trace of a process that redid a file. So when we opened a file, it got this pointer, this handler. The first allocated number was 3 for that, and we established that we already have three open files when we start working, when our application is booted, when our application is started, we already get three open files, standard input, standard output, and the error output, right? Three files are already open for us. And yeah, these file files are somewhat awkward because somewhat different because they correspond to the inputs to determine on the terminal output on the terminal. Yeah, they can be redirected sometimes, but basically the operating system handles them in the same manner it handles files. So remember, standard input is basically a file. It has some special properties. For instance, you can't seek it, you can only read it, You can't, you can't perform seek operations on the on the input, right? So yeah, there are some technical differences, but basically it's still a file descriptor. By the way, what I've shown you on the previous slide was a very simple read operation, open, seek, read and close for operations, if I want to be exact. But basically it was all about reading. Yeah, we have some additional operations like creation of the files. That's obvious because if we cannot create files, there will be no files, right? But the creation is basically merged. Usually it's merged with opening when you're opening a non existent file and you provide specific flags, specific attributes that and the file is created as an empty file. Same goes for deletions. A deletion is somewhat tricky. I will talk about it when I explain how hard links work, because deletion is slightly more complicated and always we can change the size of the file. Normally the file is extended if you write to a file. If if you're putting more data into the file and we're writing after the end of the file, the file is automatically enlarged. So the size is automatically adjusted. But sometimes you want to crop the file, you need to shrink the file. So for that you need to use a specific operation. And also the file has some attributes. I will talk about that in short order. So there are some attributes and we can change sometimes some of these attributes and sometimes actually this goes hand to hand with this point, the files are usually buffered in memory because it would be very tedious. It would be very problematic if every single operation would be translated into the disk access, especially if you're using some slow hard drive or if if the file is stored on a network file system. So in these cases it might be very tedious if every IO operation on the file will translate into the direct access to the storage or the direct access over the network. So there is 2 levels of buffering. At least one level is performed at the system level. SO11 level is at the POSIX level. When you open a file, there is some buffer associated with it and if you're loading or storing data from unto it, the operating system is somehow caching this data. And also, usually your runtime in CC plus plus, C#, Python, whatever language you're using, there is usually another buffer in the runtime which also performs another level of caching. So yeah, some of the data are stored at least temporarily only in the memory. Even if you perform the write operation and you're done with it, then the data are still in the memory. And then it may have not been yet transcribed to the persistent storage. So for that, we have the flush operation, which tells the buffers, hey, right now I would like to synchronize everything that's in the memory with the persistent storage. So I have some reassurance. Samsung guarantees that the data are actually stored on the persistent storage. So when the power goes out or my application crashes, for instance, I will have the data stored properly. By the way, the buffering is a bit tricky because usually we cannot buffer the entire file. Yeah, if you have a very small text file, it's no problem. But if you have a huge file, if you have a huge video, for instance, which can spend gigabytes or 10s of gigabytes, perhaps today if you have 8K quality or perhaps even with some 3D features or whatever, then you can easily have several 10s of gigabytes per movie, no problem. So it would be very difficult to cache that in memory if you have a simple laptop or simple desktop. So for that, it's difficult to tell which part of the file needs to be properly cached because yeah, sometimes you need to read the file from the beginning to the end, like when you are watching the movie. Sometimes you need random access over the file because it's some database or something else which is accessed as needed by some application. By the way, there are some alternatives to the file operations to the API you've seen on the previous slide. Well, in this the the operation operating manual or standard operating procedure if you will, is very simple. You need to open the file, then you're using the handle to perform whatever operations you need. And each of these operation is blocking, which means if you perform this read or this read, it will block, it will pause your execution until the data are ready. So when this function returns back, when control is returned to your main code, to this top level code, you are certain, you may be certain that the data are already in this buffer, everything is there, no problem. But sometimes you need other types of APIs. By the way, there are two, at least the most common types. One is called memory mapping. So you can directly map the entire contents of a file into the memory. I'll get back to this one when I'll explain how memory operations, how virtualization of the memory works, because that goes hand to hand, one with another. And there is also an asynchronous file IO, which is somewhat, let's say not in the mainstream. That will be the perfect definition. It's slightly on the side, but you can use it to perform some operations asynchronously, which means you don't have a guarantees that if you perform a read, the data are immediately there. You just start the read, it starts reading, it starts the transfer and returns to your code immediately. So the transfer is like loading the data on the background and once the operation is completed, you can, you can either pull it, you can, you can make an inquiry whether the operation has completed or you might get some notifications, but that's not that important. I would like just to tell you that there are other APIs. This API is like the most traditional. You can translate this to Python. Actually in Python it won't be 1 to one but but there are similar functions in Python in C#. OK, so those are the beginnings. I talked about file attributes. So let me explain that on an example because examples are always good. So this is a real list of basic statistics and attributes of a file. I've used a stats function from Linux. So I just dumped some information about this file. So let's take a look what's there. So first of all, yeah, size is obvious. So this is size in bytes. So I know this, this file is roughly 11 kilobytes long, slightly over 11 kilobytes. And it's a regular file. Yeah, that's that sounds like a yeah, nothing. But operating system or file systems usually distinguish several types of files. At the very least, they need to distinguish files and directories. Directories are specific types of files. We'll get to that. So this is a regular file, not a directory, not a special system file or special block file or something. And this is this is some identification, this identifies the device, the hardware device on which the file is stored. And this is the numerical identification I talked about at the beginning. So this is the number under which the operating system can load the file, recognize, recognize the file, identify where where the data of the file are stored in the persistent storage, etcetera. So this is the important number for the operating system, OK. This is how many links are there for the file. I'll get to that later when I explain what links are. So the links are also counted as an attribute. And now I'm getting to the more more interesting part. UID and GID is a user ID and group group ID. Those are identifications of the person and group of persons who own the file. So as you can see, you probably haven't noticed that this, this is my login. So I'm the owner of this file and it, it belongs to my group, my personal group. No, no problem there. And these are the access rights. You've probably already covered this in Linux class, right? So you know what the RW and X attributes 3 times repeated mean, Is that so? Yeah, some people are not doing so. I leave that to Linux classes because it's, it's too difficult to explain in all the detail, but basically it tells me whether I can read the file, write the file or execute the file. And finally, there are three times the access time, modify time and change time. So yeah, the access time is obvious when the file was last accessed, when somebody tried to read the file the last time. By the way, this is, this is one of the attributes that may not be updated all the time. Because if you need to update the access time every time somebody reads a file, it's a huge, it's a huge performance hog. It's it's like a very demanding on the, on the underlying structure on the file system and everything because you're updating basically everything, all the meta information are updated all the time because the operating system is accessing so many files all the time. So sometimes you turn this off if you need the performance, you usually turn this access time off. It's usual. It's not that uncommon practice in many systems and modify time and change time are the times where the file was changed for the last time. Everybody understands the difference between modify and change. I don't remember this one because modify and change it sounds like the same, right? At least to me. So yeah, hint, the first one is when the file content, when the data inside the file changed for the last time, and the second one change is when the attribute, the, I know the metadata were changed for the last time. Don't worry if you don't remember that. I don't remember that either. I always need to look that up because it's like unrememberable, but that's how they named it, so we need to stick with it. So the thing you need to remember is that there are two different time stamps, right? One time stamp is for the modification of the data itself, and another time stamp is there for modification of the attributes and other metadata of the file. That's it. OK, so this is the basic examples of most common attributes of a file. Again, the, the, the exact attributes depend on what file system you're on, what operating system you're using, etcetera. But it's fair to say that there are some metadata, some attributes that cover some time stamps regarding the file and also some privileges and ownership of the file that are very common. OK, I promise that I will say a few things about directories. So first of all, directory, as I've already mentioned, is a special type of file, basically the operating system itself, the kernel of the operating system doesn't distinguish between a directory and the file to to the operating to the kernel. It's still a sequence of of bytes somewhere on the hard drive, somewhere in the persistent storage, but the library is slightly above can read this specific file and interpret it. Because directory is a file that holds a collection, a list of entries that's a term entry. And the entry is basically a file name and the pointer to the file on the hard drive. So this is like a list of files which are stored within or listed within this particular directory. But usually the entry holds no data. The entry is only metadata that refers to the file, usually using the numerical representation like the inote over here. So in the Linux you can imagine the entry as a translation table between the file name and the inote in the very simplistic way. OK, why is why is this stored like this? Yes, first of all, it's much more efficient for look for users and sometimes even for operating system to organize files into directories, right? Because if you have like tons of files, it's better if you get them sorted into different directories. One directory is with with your stuff you need for for studying on Modfis, right? You have someone 1 subdirectory for programming class and other subdirectory for for Arduino classes etcetera. One sub directory for fancy videos right? So you need to organize your data somehow. Another thing is this goes hand to hand. You need to name these boxes. So directories can also have names and sequence of directories forms paths. So you can have a hierarchical organization, and this goes hand to hand with the grouping because you can aggregate files that belong somehow together into one location. This is not only important for you as users who need to organize the data, but it's also important for the operating system libraries, operating system tools, applications, because usually one application has all its stuff in one directory, etcetera. Yeah, the entry, the directory entry may or sometimes may not. It depends store some of the file attributes. So the entry may not be only a simple translation between a name and the inode number, but sometimes it can also contain some of the some of the attributes, depends on the design of the file system. For instance, in fact, which I will show in short order, most all of the attributes are within the entry. On Linux file systems like XE, XD, the attributes are somewhere else. The entry is really only a translation between a name and the inode and that's it. So it depends on the design of the of the file system. So yeah, to work this properly, we need some additional operations for for directories, Yeah, again, we need to create and delete. That's kind of obvious because if if we have a directory, we need a way. If we have directories, we need a way how to create them and delete them. That's obvious. Tricky part is the delete. Deletion of the directory usually means that you cannot, you either need to have an empty directory. If the directory isn't empty, you couldn't delete it. So either you have empty directories and the delete operation delete only empty directories or the deletion simply releases the files. But usually you cannot do that because directories may hold sub directories. So the way the the operating system or the operating system tools go around about it is that you can only delete empty directories. This is like a rule. And if you need to delete the directory with all the files within, then you need some special tools but some additional library which actually performs A recursive search of the directory. It deletes all the files and all the sub directories within recursively and then once the directory is empty then it performs delete operation. So if you're just using your operating system and you hit a delete button on your directory on a directory, it doesn't perform single operating OS operation. It's not a single OS call. It's actually very very huge number. If there are many files within, it may be very huge number of system calls because you need to search all the directories, delete all the files, then delete all the sub directories and then finally you're able to delete the directory itself. By the way, renaming on the other hand is very simple. First of all, renaming within the same directory, just changing the name, it's, it's trivial. It's just a changing 1 substring in in one entry. So renaming operation is very fast and very trivial. And furthermore you can perform rename as a move operation, right? Rename and move are somewhat going together. Most operating system tools are sometimes named renamed, sometimes named moved, and they do the same thing, right? If you perform MV operation in Linux, it sometimes perform rename. If you do this within the same directory, if you provide complete paths, it actually moves the file from one directory to another directory. But the benefit is that moving one file on one file system. If you're trying to move a file to a different file system to a different device, for instance, that's another story. But if you're moving a file within the same file system, it's a trivial operation. It's just taking one entry from one directory and putting it into another directory. And even more, POSIX guarantees this to be an atomic operation, so moving files within the same file system is very fast and atomic. That's beneficial. It's good to know because if you're trying to do something which needs to be safe from multi processing or multi threading point of view, this is one of good beacons that you can use to synchronize your work. And of course, yeah, you can list the members of the directory. That's like obvious feature that needs to be there. Goes without saying. An example, this is how a directory entry looks on the set FAT file system. By the way, does anybody know what FAT file has anybody used FAT file system? At least few Yeah, you probably using it without realizing if you are still using USB sticks. I'm not sure if anybody is still using USB sticks. Perhaps you have a perhaps you have a memory card in your cell phone or in your camera. If anybody uses still cameras, then yeah, probably the the the the SD card in your cell phone or in your camera may still use or is probably still using FAT. Yeah, this is just the general FAT. We are using modern VFAT extension of FAT 32, but that's our just technical details. You don't need to bother with them. So this is like one entry looks like, and actually this is like one entry which is composed of three entries. I will explain in short order. In the old FAT system, there was a limitation that a file name has 8 characters plus 3 characters for extension. That's it. So you are limited by the size. Your file name may have only 8 characters. That's it. Nobody will ever need more than 8 characters, right? So remember that when you're naming your next document. This is the document that I've created On this date and it contains this, so remember that. And FET needs to somehow remain backwards compatible with MS-DOS who was still relying on this and also needs to support newer operating systems like Windows. So they need to make it compatible both ways. And what they did is that if you need a larger, a longer name for a file, it spans over multiple records. So it creates A shortened version of the file name. So let's say we have a file name, which is called the quick brown fox. It's definitely more than 8 characters, right? So the name of the file will be the quick something one. This is, I think, tilled this is never mind and Fox like the end because the last three characters may hold the extension. So that's why the three, three last characters are copied here. And this is like a short version, short name of this file. If someone needs to for whatever reason, access this file system from ASDOS or some very old operating system that doesn't know this extension. And for modern systems, the name is copied into two additional records which are like attached to it, but they don't hold all the data, they just use most of the record to store the letters. And as you can see, the letters are stored 2 bytes each. Here the letters are in normal answer in normal SK1 letter per one byte. Here there is one letter per two bytes because it's stored in UTF 16. And yeah, the Quick Braun dot FO jump X and then there is a 0 as a Terminator of the string and the remaining positions are padded with this value. OK, so this is how we store longer values. What can you notice on this is that there are some additional information like the metadata, create date, create time. Yeah, the metadata of the file are stored directly within this entry. And most importantly, these two items are the most important ones. First cluster. This is the index to the table where the data are. There is some table on the FAT, I will get to that. So this is where the first data block of the file is stored. This is very important so we can find where the data of this file actually are. So this is like the translation we were using with the inode. So similarly we got the first cluster index. So translation to some number where we should find the data and also the file size. So we know how many bytes we can read from this file. OK, this is just an example here, a very old example because that is not that much use anymore, but still it's valid because you get some glimpses and some notions of how this stuff works. OK, so this was FAT. Let's move on. File system or files will be nothing without some file storage. So they need some stuff someplace where they can be stored normally. Usually a file system resides stored on some traditional file system storage, like a secondary or external memory hard drive, SSD drive. By external, I mean it can be an SSD drive connected via USB or USB stick, for instance, or SD card. That's that's pretty much all the same. By the way, you can also have a file system which is directly in the main memory. Yeah, Why the hell we would do that? Because I told you previously that one of the main reasons why we're creating the files is that the application can store them and they will be persisted. They will remain there. They will survive a power outage, they will survive a reboot of the system. But definitely RAM will be erased, will be lost when we reboot or when we lose the power. Why the hell we will store our data, store our files within the RAM? Would anyone venture? I guess, Yeah. I mean, do you understand this? Can you give me an example of this? Yeah, I know you can read. This wasn't test of reading. I I was like, what? What the hell are temporary files? But therefore what? What's the purpose of this? Yeah, but examples, examples, examples, examples. Are you using temporary files right now? There are many people with laptops. Are you using temporary files right now? Maybe, yeah. On the other hand, cookies for websites are very likely stored in the persistent store, unless you're in in the anonymous ***** mode. So unless you're doing something very naughty on that laptop, it's unlikely that your cookies are stored in a temporary file because you usually want the cookies to survive. If you close the browser and then reopen it, the cookies need to be still there. So cookies are not a good example. When you're installing something, when you're downloading something, when you're unzipping something, you need to extra file where you have a zip archive and you need to take something out of it. You need to just take a look at it. So you just temporarily unzip it to another file, take a look at the file and you just throw it away. So for that, you don't need the persistence, right? You can do this in the memory. And why we are doing this? Because for many applications it's easier to still use the same API for files, even for temporary files, not to allocate their own memory. They used to use some API for files, so they used also for temporary files. OK, now the possibility is network storage. You probably already have seen it, because today many people have their files stored somewhere in clouds, right? If you already used some clusters in Linux classes, I'm not sure whether they do that. Then you probably accessed your home. Actually, you're using them in the labs. If you log in in the labs, your home directory is on some shared network storage. And if you, it doesn't matter on which PC you log in, right, you will still have your home there because it's stored somewhere on the server and all the data are transferred there and back as needed because it's a network storage. And also there are some virtual file systems. So basically many operating systems, Linux especially uses file system extraction, file extractions to create artificial files which are not actually persisted anywhere. But they are attached to drivers, they are attached to pieces of kernel and they provide additional functionality. For instance, by reading or writing these files, you can get some functionality, you can get some information, you can perform some settings to the system very quick. Dev null is like the one of the most profound files in the in the Unix imposix file systems. You know what dev null is? Anybody knows? Yeah, you probably heard that in Linux. For those of you who are not not nodding, just a quick reminder, this is a file. This is a dumpster. If you need to dump anything anywhere and you need to erase it, you you just dump it to dev null. So all the right operations in devnul are simply ignored by the system. It's just like a eraser. And also if you're trying to read from devnul, it will serve you zeros. So if you need a safe and sound source of pure zeros, you can just read devnul and you will get as plenty as you'd like. Similarly, random will give you random numbers. So if you want some randomized numbers quickly, so you just read as many as you need from your random, it will serve you some random garbage. Another example, if you read this file, you will get a text formatted description of your CPUs. Just try it. Just try to get this file and you will get some basic information about the CPU course of the system you are presently logged into. OK, so files. Another topic which needs to be filled into this puzzle are file links. Actually we have two types of file links. The first one is hard links. Hard links are somewhat like file entries which are duplicated. So hard links from the perspective of the file system aren't even links in this in the simplest terms, it's just duplicating entries for one file block or one. I note I will explain on the whiteboard. It would be easier. Let me just, let's just say you create a file somewhere in the file, somewhere in some directory, it doesn't matter. And this entry translates this file to an inote. Hey, this jokes, let's say 42 because 42 is a really good number for an inote and I don't know, I don't want to give you 2 long numbers. So there is an idote structure where all the metadata are and also the inode holds some references to the data blocks so we can read the file. We'll get to the structure later. So basically we can through this entry we will get the inode and through the inode here we directly have the metadata and through the inode we can get to the data blocks of the file. But I can do this. I can create a. I can create another file, another entry in another directory which also holds Inote 42. No problem. We can do that because this is just a number, right? So we have two entries pointing to the same inote. Technically and for all instances and purposes, these two files are like the same file. It's like the same file under two different names and that's what's called a hard link. You can hardly. Well that's a good point. It's a hard link because you can hardly distinguish these two files apart and if you write something to 1 file, it will magically automatically appear in the in the other file. Actually there is one way how to find out that there are multiple links pointing to the inode and that's the link count which is stored within the inote structure. You may have noticed it I I've pointed out over here. This is the how many links are pointing to this inote. So if I create this properly, if I create this properly I need to increment this value within this inote structure. Why we need this? Please volume up volume if you want to remove a file. That's right. Yeah, actually it's the other way around. But the the the reason is the same. So if I need to delete a file, if I want to delete it, if I'm trying to delete this file and I if I remove the inote and all the data blocks, this entry will become very unhappy. Actually the user will become very unhappy once it tries to access this entry because it will point to a non existing inote and that's something that shouldn't happen. So what happens here is if I try to delete Foo, it won't delete the inote, it will remove this entry and it will decrement this number and the inode and all the data are released once this number reaches 0. OK, so as long as this number is greater than 0, the inode and the data are not removed. So if I have multiple links, deletion of a link doesn't delete the data at all, it just deletes the entry and decrements a number. Only the last deletion deletes the file. That's also why deletion of a file is named unlink in many systems, in Imposix for instance. So you may have noticed that if you try to delete a file using normal operations, low level operations of POSIX, the name the proper name of the procedure is unlink because you are unlinking the inote and the erasure is automatic once the inote reaches 0 links. By the way, important notice, if you perform F open or open doesn't matter on this file. This also increments this link number. So the inote and all the data remains there as long as there is at least one link. And if you even if you delete all the entries, as long as the file remains open, it will be there. This is one of the tricks you can use in programming. If you want a temporary file for writing for some operations, for some temporary data or whatever, and you don't want this file to be accessed by other applications, you just create a temporary file, open it, unlink it, and as long as it remains open, you can use it as a temporary file no problem. But no one else can access it, no one else can seize it. So it's one trick you've just learned if you're dealing with temporary files. OK, so this is hard links. SIM links or soft links are somewhat different. They are basically text files which holds a path to another location. So basically this is like a not transparent link. This is like an explicit link where if you access this link, you need to read the text within the file, which is a normal plain text file, and then use this link as a new location, as a new path where you need to be traversed. So any application that's reading the SIM links need to be aware of them and able to translate this new location to a new path and open another file, etcetera. But usually most of the applications do this transparently and high level functions of the operating system, libraries, et cetera, also can follow similarly transparently. So usually this process is somewhat automized within the libraries. OK, Finally, before we get to some examples, let me summarize what a file system is. So far I've been explaining different parts of the file system, so let me summarize it all together. So basically file system is a set of algorithms, data structures, protocols, everything that's needed to hold, represent, access, store, and everything you need to do with files and directories. So this is like if you sum it all together, you've got the file system. Usually file system is giving you some abstraction, some virtualization, some data structures to abstract files and directories. And by the way, usually operating systems perform abstraction of virtualization of file systems as well. So if you're handling any file system within Linux, it's translated into some virtual file system which kind of encompass all the common things from the file systems. So if you have a different file systems like X or FET, they have some commonalities like they use string file names, they have data creation time for date and time for create. Sorry, time stamp for file creation, that's what I wanted to say. Both of them. So stuff like things like these are common. So even the operating system is trying to virtualize that file system has several responsibilities. First of all, it's responsibility for handling all the naming. So how the directory formatting is done, how the path is are translated into the inote or whatever data block indices are required by the kernel to read the data on the persistent storage. That's all responsibility of the file system. Also all the management of all the data blocks. So basically file system is operating on a some memory storage, some persistent memory storage. So it requires operations like read block number 321, write block number 826, etcetera, but that's it. Everything else is managed within the file system. So any additional files, data structures, any additional bitmaps or linked lists or whatever is needed to maintain which blocks are not allocated, which blocks are already allocated, etcetera. That's within the preview of the file system. Local file systems, the most common common file systems you can find, are usually stored in a normal hard drives, like magnetic hard drives. Yeah, I doubt that anyone has magnetic hard drive here. It would be doubtful because if you have new enough laptops, you're probably using SSD hard drives, but also some removal media, the SD cards I mentioned before, etcetera. Network file systems are somewhat different. They are usually designed for the, for the perspective, for the, for the usage over a network. And usually network has much higher latency than the persistent storage on your local computer. So these have some additional features. For instance, NFS is designed so that you don't have to open files within within the file system itself. So you just providing the some general identification for the file every time you need to access it. So you can access multiple files simultaneously, it doesn't matter how many files you're trying to open etcetera. Also if some, if the connection is interrupted for a short period of time, it doesn't matter because the NFS will just simply recover from from that. So it's a very, very powerful system on Windows, usually using Samba, SMB. This is also, but SMB is somewhat more clumsy because it's basically like an RPC over basic normal file system API. So it's somewhat different. But these are just examples of file system you can see and you can study if you like. I will give you 2 examples in a closer detail. The first one is FAT. You have already seen the FAT directory entry. That's a different part. So let me show you how FAT manages the files data. That's probably the most interesting part of FAT file system. By the way, knowing this plus knowing some details like how the boot record and the initial structure of the hard drive of the persistent storage is laid down is enough for you to be able to write anything, any driver, any, any piece of software that would directly utilize FAT. Side Story, I've when I was younger, I've accidentally erased one of my hard drives. It was like I was doing a complete reinstallation of my, of my PC and I've accidentally plugged as I was shuffling my hard drives. Yeah, I was really physically shuffling my hard drives because hard drives back then were quite small. So I need three of them to manage all my data. So we're shuffling them and I accidentally connect one hard drive to another location. So it appeared under a different letter in my Windows system and I accidentally erased it. Fortunately, it was filled with the data right before that, so it was like all the data are were stored very regularly on it. And I was using FAT file system. So I need to spend like a week writing my own software to carefully extract all the data. Because technically when you perform quick format, you don't erase all the data, you erase only the metadata and the remaining data are still there. So I need to reconstruct it. The FAT table I'm going to show you right now from glimpses of the data on the hard drive. And it was possible because it's a very simple file system. OK, how it work basically besides the boot record, which is kind of boring, there are there is something called FET table. This is the most important part of the FET file system. It holds all the indices of all the blocks where they are stored. So the data there are two copies of the of the FET table. So if one of the copies gets corrupted, you still have the second copy, it's just for the safety. And after that, there is the root directory. So the root directory is basically a file located on a fixed position right after the fad tables. And after that there are data blocks. So these data blocks are data blocks of all the files. And each fad table is basically a index table which holds one number for each data blocks in this area. So every data block in here has a corresponding number in the fad table. That's it. So it's very simple, for instance, to detect which blocks are empty. Empty blocks got zero over there. So if you just scan for all zero blocks, you will find all the empty space of your hard drive. Very simple. And then again, we need to somehow reconstitute the data of each file. And remember, file is basically a data stream. So the file starts on an index which is stored within the directory entry. Let me just scroll back. This is the number. OK, so we take this number which points us to the first location within the Fed table and it's also the index of the first block. We need to read from here, right? And if the file spans over multiple blocks, which usually does because these blocks are usually something like 512 bytes wide. Sometimes actually on the smallest devices, it was like 512 bytes wide on a larger, on a larger devices, they can be quite large. They can be like 1632 kilobytes wide. It depends on your on your device and but, but that's not important. Important is that these blocks are stored as a linked list and this linked list is stored within the indices of the fat. So basically if I have a three as the first number of the first block, I need to read block number three from here and then I need to take a look at position 3 in the fat table where I find the index of the next block. So then I need to read block 10 from the data and I also take a peek at the position 10 in the fat table where I will get the number 15. OK, so the next block is 15. So I read block 15 from this this area and then I go to position 15 -, 14, etcetera, etcetera. Once I've reached -1 and -1 is like a marker, then the the, the link this ended. So, so the position 14, the block 14 is the last block that I will be actually reading from the from the data area. And it's like a termination marker in in the Fed table. So I will have to read no more. OK, by the way, I can somehow determine the end stop also from this information, right? I have the file size, so why it's? Why it's redundant? Why is there file size and always also there is this this marker which terminates the the the link chain? Why I need both of the? Do I need both of them? We sorry, we need. Yeah, that's one possibility. But even if I don't have to look at all the blocks, I need to look at all the positions in the fat table. But if I want to skip first three blocks, I can. I don't have to read them from here, I just need to read the fat table. And actually the fat table is usually cached in the memory, so that's not the main reason I can do that. Even Even so, remember that these numbers represent whole data blocks, which can be 10s of kilobytes long in the worst case. And usually files are not that well aligned. If you have a text file, it can easily have like 42 bytes no problem, why not? And if you just want to read the 42 bytes and the granularity is like in kilobytes, then we need this additional information like how many bytes we want to read from the last block, right? In this case, the first block, because 42 is too, too small a number. But usually the size of the file isn't aligned to the size of the blocks. So you need this additional value like where the where the file actually ends within the last block. OK, another example is X2. X2 is a file system which is being, well actually X2 itself isn't any more used. I think we are using X4 usually or some more elaborate systems. But X4 is still being used on Linux. And X4 is basically X3 with journal and X3 is just an extension of X2. So if I show you X2, you will be pretty much in the picture. You will be pretty much you will get the fundamentals of this system covered. We don't need to get into the details how it changes in X3 and X4. So it uses inotes. We already know that you may have noticed on the previous examples. So the inote is a structure, it's called index node and that's a structure which holds the metadata and also it holds some higher or it's like it embeds some. Data structure which allows us to identify the data blocks on the on the drive. So it also somehow identifies which data blocks we need to read when we need to access the file. And directory is very simple, unlike. In fact directory is very very simple table where the names are translated into the inode numbers. That's it. OK, let me give you a better a better picture because this is much more readable than the text. So first of all, if we have a file system, the X2 file system on the hard drive, it usually is divided into block groups. So for easier management and for let's say better memory locality, it uses something called block groups to aggregate the data more closer together within the hard drive. And also these block groups are easier to manage. So they are not that big. They don't usually spend terabytes. They usually spend, I don't know well, in the past it was like 10s of megabytes. Now it's maybe more, but they are not that big. And these have a very fine structure. First of all, there's a super block and a descriptor. These two are like a regular data structures that are always there. And by the way, super block and the descriptor are present in all the blocks. So super block describes, it's like a structure that describes the entire file system, important information, meta information regarding how large this file system is, how large the blocks are, how many block groups are there, etcetera. So all this information is there in the Super block, and this super block is duplicated in every block group. So if the part of the hard drive gets damaged, you can still identify the rest of the data because the Super block won't be lost. Similarly, the descriptor will describe how large is the structure. So since all the block groups are the same, should be the same. Then the descriptor should be the same or almost the same and afterwards there are two bitmaps data bitmap and inode bitmap which identify which position in these two tables. In inode table and in the data blocks area are occupied which are vacant so which you can use and which are already taken and these two are the most. The data blocks are the same as in the case of FAT. Here are the real data airlines stored one after another. And how we find out which data blocks are used by which file? Well, that's the part of the inote structure besides the metadata like the timestamps. The inote holds this sequence, this table with block indices. So each line here is a number of a block, right? And these block numbers are divided in a strange tree like structure. The 1st 11 are direct links, so these are direct block links. So if you have a file which takes only up to sorry 12, it's from zero. My mistake. So first 12 blocks can be accessed directly. So small files use only one level of indirection in the inode table. In the inode structure, you can immediately get the indices of the block. So you can immediately read the blocks. If the file gets larger, we add another level of indirection. So the block 12th, 13th block has one level of indirection, so there is another block. And this block is a data block which is filled with links. So this has the same size as these blocks. All the blocks have the same size. But this one is special because it's not, it's not filled with the data, it's filled with references. So it's a sequence. It's a table also filled with block numbers and subsequent after the 12 blocks. So this should be named block 13 actually. So block 13 etcetera are over here. So you need one level of indirection more you need to read this block and then you can read all the other remaining data box. And if it gets even larger you get 2 level in direction. So this is a block which points to blocks and three level of indirection. So it's like a small files can be accessed quite quickly, quite directly, larger files slightly slower. And if you get very large files then this tree gets bulky. So this was an example how X2 works. By the way, this and this should be might be on the test. So it's like a good, good idea to know approximately how this works. Because if you don't know how to find which blocks on the FAT table or which blocks in the in the X2 needs to be accessed when you are given a file, then you might have a problem. A few more words regarding the storage. Yeah, this is like, by the way, everybody know how magnetic hard drive still looks like. So if you know that, then you know that there is a spindle. And on this spindle there are multiple platters. These platters are made from some. I'm not actually a metallurgist, so I don't know exactly what they are made of, but it's a magnetic material and these heads which are placed on an arm, can perform reads and writes using some electromagnetic operations. Actually nowadays it's very, very complicated because there is also some laser involved that preheats the the platter. It's very complicated from the technological point of view. But, but from the, let's say abstractive perspective of our of us programmers, it's very simple. You need to place the arm to the right position so it's above the correct track and then you can read or write this track or a segment of this track which are called sectors. That's pretty much it. The trouble is that when you when you want to access something, you first need to put this arm into the correct position and then you need to wait for the data to rotate towards you. The rotation time of this of this whole of all the platters actually is somewhere in this range normally. In my old days all the hard drives were using seven 7200 RPM. Sometimes the nowadays actually we are trying to be green. So it's better to lower this speed a little to 4 or 5400 or something about it because it it consumes less energy. It doesn't take too much energy to rotate them. But high performance hard drives can go either up to 10K or 15 KRPMRPM rotations per minute, right? 15 KRPM is fast, right? It's 5015 thousand per minute. So if you just divide it by 60 right, you got you got the picture. By the way, this is like we cannot speed this up much further. There were some experiments with filling the hard drive with additional some some helium or something because the trouble is that the head itself is hovering like 5 nanometers nanometers above the platter and that's quite close. It's very damn close to be accurate. So there are some very specific hydro dynamic properties being observed because as the platter rotates it creates like a small wind right above it and the head itself has some hydro dynamic shape. So it basically floats on the wind, which is created by rotating platter. Don't ask me, I'm not a physicist. But somehow miraculously it works. But if you increase the speed, it, it stops working because the the the wind starts to be more turbulent or something and the the heads are starting starting to be shaky. So we cannot speed this too much. We cannot crank this up much further, but this is basically how hard drive works. By the way, if nobody has seen hard drive live, this is magnetic hard drive. If you haven't noticed, it's just slightly older than you might be used to, but it's still magnetic hard drive. This is, by the way, I think this, Yeah, 10 megabytes. So it's huge, right? OK, magnetic hard drives, as you sorry, as you witnessed here, these are problems. Both the movement and the rotation speed are problems because they are slowing things down. By the way, do you know how much does it take within the speeds if you before the data, before the whole track can be read, before the data rotates towards you, roughly what order is it? Seconds, microseconds, nanoseconds, picoseconds, milliseconds, whatever. Yeah, it's units of milliseconds. So it's like, I don't know, 5 milliseconds, 3 milliseconds. I think this is 3.1 of them is 3.6 milliseconds. I don't remember, but it it's somewhere in this order. So it's milliseconds. How many instructions can you crunch on your Pentium? Oh, sorry, on your on your CPU within 3 milliseconds, right. Millions at least. And this is the same adjusting the position of the head, it usually also takes at least milliseconds, sometimes even longer if the path is longer, sometimes even longer. So yeah, it's slow. There were some algorithms that tried to speed things up. One way was how to speed things up was to create better scheduling algorithms so that the head doesn't have to move that much or we trying to re pre read the data all the time. So basically nowadays when the data needs to be, when a track needs to be read, the, the hard drive itself always reading the whole track, not just waiting for one sector, pushing the whole track into the buffer just to be sure because maybe the next sector will be needed shortly. So it's like there are many optimizations in place. I would like to show you a few algorithms that were used in in the past days. Nowadays they are not that important because we are switching to SSD. But still they are there. And some of them are interesting from other perspectives. So first of all, if you if you handle all the requests on your hard drive, Yeah. By the way, this this line represents the radius of the of the platter. So this is like a centre and this is like the edge of the platter, OK. And these stops represent the requests for tracks which tracks needs to be read or written. So if we just simply process them first come first serves, it might create a very unoptimized access because for instance, some of these may be far and you need to move reposition the the heads too far from from each each request. But on the other hand, there are no additional, let's say unfairness is added by this algorithm. So everybody gets its turn. The requests are served in the order they were made, which is the fairest from the perspective of the applications, etcetera. Another possibility would be, yeah, we can, we can minimize the seek time, right. So let's just say, OK, we, we take the shortest seek time first. Let's assume that we already have all the requests in the queue. If you don't have the queue, then it doesn't matter, right? But if you have the queue, we can we can optimize and reorder the requests so that the the based on the initial position, the short request, the nearest request will be served next, which minimizes the movement of the heads significantly. Unfortunately, it's very easy to create starvation because it's possible to keep the request on one side of the platter, and if there is another request on another side, it might wait a long time before actually the hats will get to that. So it's not a perfect algorithm. Another algorithm is well known as an elevator algorithm. Actually this algorithm is implemented usually in large buildings. Actually a version of this algorithm to be accurate to collect passengers into the elevators because it would be a bad idea if any passenger could move the elevator to any direction, right? Usually if a passenger arrives and wants to go down and then another passenger arrives and wants to go up, it would be a bad idea if the second passenger can change the direction of the elevator, right. So what what it does it, it keeps, it keeps like a pointer which direction we are moving and it keeps the direction as long as there are requests in the direction. So basically it it creates, it orders these requests into two parts, one within first direction. And once we reach the end of the disk, we will start returning. And once we reach the center, we will start returning. So this reordering is somewhat better because it kind of collects the request as it goes. On the other hand, sometimes it's not perfect. As you can see, some, sometimes there are long gaps between actually, especially when you flip the side, flip the direction you're moving. By the way, it's here. Yeah, there is a version of this of this algorithm called Silcroscan, which is like the elevator algorithm, but when it reaches the edge of the disk, it just zooms back to the center and then just stops from the bottom up. Because it's sometimes it can be. This operation can be performed faster than it would appear. There might be a special, let's say operation for the heads to just quickly flip from one side to another side and hit some cushion there or something and then start always seeking precisely from the center to the edge or vice versa. So sometimes it creates more uniform. Also, it can create more uniform time to compare to the elevator algorithm. There are some variations on the theme. For instance, you can you can have a look and see look which is analogic, which are two analogical algorithms. But they try to avoid the edges of the of the platter because both edges, both the center and the edge are somewhat more difficult to handle. On the other hand, it creates additional starvations or it creates additional areas which cannot be used regularly. So it's not not that much used, OK, this was just to give you a glimpse that there is some, some there are some difficulties going on within, underneath within the hardware. And another thing you should be aware of and that's more interesting because it's much more modern is how solid-state drive works because SSDs are still being widely used and they will be probably widely used in the foreseeable future. All your laptops right here probably have SSDs, right? So this is to give you just the notion how this piece of hardware is constructed. So first of all, SSDs are made of memory, which is not that dissimilar to RAM. So it's made of some transistors and these transistors are different to regular RAM. So they can keep their own charge. They somehow can stay in the the last locked state. Don't ask me how, I'm not not this is beyond my knowledge. So somehow if you set the transistor to one position, you can read it many times without resetting it. That's important. Unlike DRAM, which needs to be recharged periodically because otherwise it loses its, its coherence, it loses its, its charge, these transistors will keep stuck until you apply extra force to reset them to, to change them. And the trouble with that is that if you perform well, not, not the the reads also, but mainly if you perform writes, if you're trying to change the, the state of a transistor, it, it, it gets damaged, it, it's slight, it gets slight small damage. And unfortunately this damage is kind of cumulative. So you cannot change the state of all these transistors too many times. Basically each transistor can be reset like thousands or 10s thousands of times, something like that. So not too much, right? This means that if you have like this time, this amount of erase cycles, then the mean time before failures is still would be still high if we apply some additional techniques. So if we don't damage one particular transistor too much, but if we try to even the damage among all the transistors, then it it still can create decent hard drives and it actually does because we are all using them. So we, we are not troubled by this fact. You are living in a in a harmony, being oblivious to this impending doom of your hard drives of your data. But it will happen. Be sure of that. So how it's organized, it's organized in two level hierarchy. It's organized in blocks and the blocks comprise of pages. A page is usually some kilobytes wide, so pages can be some somewhere from 2 to 16 kilobytes roughly there. And blocks usually have hundreds of pages, like 256 for instance. So if you if you just multiply this, then we can follow the conclusion that the blocks usually have roughly megabytes somewhere there. OK, so what's the trick? The data can be accessed by pages, so one page can be read or written at any given time. But by written, since it's named, we can only write zeros. We cannot write once, we can only flip 1 to 0, but not vice versa. So basically, you can write a page once and then you cannot write it again. Because yeah, technically you can perform a very specific update. You can apply some additional writes that will flip some more bits from 1 to 0, but that's a very specific operation. This is not being widely used, so the only way how to reverse it is by erasure. And the erasure procedure flips all the bits back to once again. So you can erase a block together. And that's the difference. You are always reading write per page and erase per block. So you can take the entire block of pages and wrestle all the bits up to once so later they can be write again they can be flipped to zeros again. That's why it's called NNT. It's negative. The reset state is to zeros, and it's end because we are ending zeros, we are flipping bits to the zeros when you're writing. That's it. And the trouble is that especially the erasure procedure needs to apply extra power, and this extra power is what damages the transistors. That's why it works so clumsily. But if if this is handled properly, it still creates a very decent piece of hardware. It creates a very decent persistent storage because it's very fast. When you compare this to the magnetic hard drive, there is no rotation part that there are no heads moving. Yeah, So it's very fast. It's very, very efficient. And also there is the power efficiency, because you need to apply extra power only when you're erasing them for reading, you need much less power. And yeah, it's much less power than if you're rotating something. The rotation part is very, very costly for from this perspective. So let me give you some examples how this works. Basically, you start with three blocks. And by three, I mean these blocks have all the they are erased, so they have all the bits set to 1. All these three blocks are ready to receive rights. And at the beginning, you just write 4/4 pages to the first block, to the block what's block X. So you write ABCD pages to the block X, and yeah, they're there. You cannot erase that. You cannot overwrite them usually. So if you need to update this data, then you need to rewrite it. Let's say that we perform some modifications to the file which is stored here. So basically we need to store the additional data. In this case we are writing additional EFGH pages in here and then we if we perform some modifications to ABCD then we create the new versions of ABCD. Over here, it's ABCD with Apostrophe as a new version of these. And these blocks are just marked as unused. So there is smart controller running all over the place. So the smart controller controlling the access of individual blocks. And this actually performs. This controller actually performs remapping. So it remembers that A is no longer here, but A is. The new version of a is here. So when anybody asks for a, it will be over here. OK, basically this controller is very smart. It's like a small computer running within your computer, which just controls the hard drive, the SSD drive. And now if we want to erase these four blocks because they are no longer used, we don't want them. We want to reclaim this memory. If we want to reclaim this memory, the only thing we can do is to copy the remaining valid blocks in valid pages, sorry, from this block to another block without the four block 4 pages which were erased. And afterwards, we perform erasure procedure on the first block on the block X to set it free altogether. Yeah, very clumsy, right? This procedure has several disadvantages. Most importantly, pages are being rewritten many times during this garbage collection procedure that tries to reclaim the erase blocks, which adds to the cumulative damage which we are doing to the to the SSD. So these reclaim operations need to be performed in a smart manner. The controller needs to be really smart to do this only when really needed so that these erasures are not very frequent. That's one one like an issue that needs to be resolved. By the way, this algorithm I was mysteriously talking about is called wear leveling, that the controller is trying to evenly distribute the workload over all the blocks on the on the whole hard drive, on the whole SSD drive so that each block is damaged equally. So it not happens that you, you just keep damaging one or two blocks repeatedly many times, but it evenly shares the workload over all the blocks. And the second thing that's there is over provisioning. If you buy, I don't let's say 256 gigabyte hard drive, SSD drive for your laptop, right, They're actually selling you more. They're selling you like 300 gigs. You just don't know that because the extra gigabytes are over provisioning. So they are hidden from you. So when some of these blocks get damaged beyond repair, so when it's erased and it no longer can retain all the bits up to once, so it's marked as damaged forever and then another block from this reserve from this over provisioning area is taken and is replacing the damaged block. So you can run longer than expected with your hard drive without noticing that some parts of your hard drive are already damaged beyond repair. That's also normal procedure. By the way, there are tools like Smart Tools you can apply to check what's the condition of your SSD drive. And these Smart Tools usually read how many of the blocks were taken from the over provision over provision part, how many blocks are inadvertently damaged beyond repair. So this is like how you can check for the status of your of your SSD drive. There are also some operating system solutions which allows us to even the load. For instance they are specified specific flash friendly or SSD friendly, SSD friendly file systems that will allows us to write the data on the hard drive in a more friendly manner. Basically they usually depend on something which is called a log structure. All the operations that are performed on the hard drive are not stored within the files, but they are stored within the log. And log is like a very huge continuous file where all the operations are edit appended. So it's like trying to evenly override the data of the whole whole file. I'm not going into the details, it's it's quite complicated, but just to give you a glimpse how this, how this might work. And second thing that's there is some of the operations need to be added. This is an example of an operation that was negotiated between the vendors of the hard drives on the SSD drives and the operating system designers. And that's the TRIM operation. It's a special command which can be used by the operating system to render some blocks invalid. So to tell the the SSD that some of the blocks will no longer be used. Yeah, because if you're erasing a, a a file, you're not erasing the data. If you erase this file, if you erase this inode, you just mark these blocks as reclaimable. You just mark these blocks that they should be retaken at some point, right? But you're not erasing them unless you're doing some secrets. Unless you need to handle some secrets. Unless you need to override them with some random data for protection. But usually just keep them as they are. But the SSD doesn't know that, so the SSD is trying to do its best to keep them alive. It will be. They will be copied during the garbage collection. So the TRIM operation allows the the operating system to announce that some of the blocks will be will no longer be used and the SSD doesn't have to support them anymore. So they can be reclaimed as a free space during the next garbage collection session within the SSD. OK, I think this is a good place where we can. OK, let me finish this slide and then we will take a break. OK, so this is like a fast last slide for the for the hard drives and, and file systems and everything. So it's like 2 more issues I haven't covered yet. You may notice that I'm trying to put a larger piece of puzzle from many, many pieces because we don't have too much time for this. So one thing that you may have noticed, you may have known about is hard drive partitioning. If you buy a hard drive, solid-state drive, magnetic hard drive, doesn't matter. You can actually place multiple file systems on it. You probably know that, right? I used to do this all the time because if you have a large hard drive, well, it's not that important anymore. But in the past, it was very important that you reinstall your Windows every few years. If you had a Windows like 98 or Windows 2000, Windows XP as well, it was very prudent to reinstall the Windows every now and then because it got calm after a long time, because all the updates and everything, it got messy. So with Windows 10 and 11, it's not that important anymore. But nevertheless, I still tend to divide my hard drive to a operating system part where the operating system and the applications are and the data part and the data part can be done easily backed up. And I know that if I want to keep all my data, I just keep the data part and that's fine. The operating system part isn't that important. It can be replaced, it can be reinstalled. So you can do that. You can just divide a hard drive into multiple partitions and each partition can have its own file system. You can even have like a multi boot solution. So you can have a partitions for NTFS partitions for Windows and on the same hard drive you can have XT partitions for Linux no problem. You just need to adjust the beginning of the hard drive when the master boot record is or the nowadays the GPT record is. This is not the large language memory model. This is, this acronym is much, much older than large memory models. So this is a different GPT. It's just a table at the beginning of the hard drive which tells you which partitions are on the hard drive. And another thing you can do is the other way around. You can master, you can join, you can bundle multiple hard drives together. Again, hard drives, SSD doesn't matter and you can create an array of hard drives. It's usually called rate redundant array of inexpensive disks. Yeah, I used to laugh to this word because when I was younger than the word inexpensive wasn't really applying to me, especially when I was a student. So yeah, it depends on how much money you have. If you have too much money, then everything is inexpensive too. But this is the way how you can provide either illusion that you have a large hard drive, then you can have, because there are always some limitations. Right now you can buy, I don't know, 2830 terabytes per hard drive, something like that is maximum, maybe less, maybe more. I'm not following the trends too, too rigidly. But yeah, if you need large hard drives, you can collect multiple of these hard drives and create the illusion you have a large hard drives. That's called J Bot. It's not there. So it's like concatenation of the hard drives, but also you can connect them. You can you can interleave them in a more clever manner. For instance, you can create a rate 0, which takes two or more disks and interleaves them per sector or per block of sectors. So when you're reading or writing the data, the operations are distributed evenly among two disks. So you double the speed of reading enough writing as well. If your controller is fast enough, you can really double or multiply. If you have multiple disks, you can multiply your operating speed. Very useful. But then again, you're creating a more dangerous situation because if one of these files, one of these drives fail, you lose everything. So it's not always the best option. It's a very good option for scratch drives. If you really temporary storage for huge scientifical data and you really need to process them fast, that's perfect solution because you don't keep the data forever there. You just need them for some computation. So it's it's better if you can access them fast. The other way around is that you have RAID 1. You have two disks and they get mirrored. Both disk retain the same data. Every write operation is sent to the the same is sent to both drives and both drives perform perform the operation the same. Still write 1 can double your speed when reading because when you're reading you can request the data from both drives because they're mirrored, they're the same. So you can you can request half of the data from one OneDrive and another half from the second drive. So basically you're doubling your throughput for reading and there are more elaborate ways how to create rate. For instance, rate 5 creates a block of n + 1 disks, and the N disks are used for data and the plus one disk is for some check sums. It's slightly complicated than that, but basically if you lose one of these n + 1 drives, all the data will be still intact. So if you like use 4 drives and one extra drive, you have 5 drive. So you have the capacity of four and the extra drive will provide the the check sums. So if any one of these five drives fail, you still have the data. So it's you. It's like a safety precaution because sometimes the hard drives fail. So that's it. Sorry about the sorry about the gap. I will suggest we take a 5 minute break. We'll suffice. So if you need to refresh yourselves, go to the restroom, whatever you need. So please do and we will resume in five to 10 minutes based on how fast you will be. OK, I realized it would be difficult to sit here for another hour with a hood break. So please take a break and we will resume with another topic. Hopefully this will also resume the recording and let's switch to another topic which is virtual memory. Technically, from the perspective of operating systems, this probably the most important topic because it will give you insights into many things that are happening inside your computer. That also includes memory allocation, file operations, etcetera. So far we will. We were working with the assumption that there is some memory which is given to the process. When we were starting the process, I told you about the segments of code, segments of data like constants, etcetera, which are somewhere in a linear memory. But I was talking about things like there are multiple processes running together within the same operating system on the same host, and they need to somehow be separated one from another. And that's what this old concept, the whole concept is about. Technically, from now on we will distinguish two types of memory. When I was talking about memory, I was talking about virtual memory. So that's the memory that applies to regular applications. So regular applications are running in virtual memory space. They are given the illusion they are living in a dream world. They think they have all the memory for themselves. They have a huge memory space, 64 bit memory space only for themselves. But that's a lie. And this lie is made possible by hardware and operating system working together. Because the real memory, the actual memory, the DRAM you plug into your CPU to your main board is the physical memory. So this is the real memory. And there is a mapping. There is a translation mechanism that allows translation between regular pointers of regular applications, the virtual pointers into the physical pointers into the real memory. So every time CPU accesses memory in the user mode, it always perform this translation. So every access to memory goes through this translation mechanism. So the CPU basically translates some pointers which are given to it to load instructions, to load data, to store data, whatever into the physical addresses which are then going to the buses, which are then used to access the real memory. That's the main concept. That's the main notion. All the memories, both memories are always one-dimensional. Actually there are ways how to ensure how to create multi dimensional virtual memory like segmentation where the addresses are actually 2 dimensional. You have two parts of the addresses, but that's not important. Physical addresses needs to be always one-dimensional. This is just a sequence of bytes concatenated 1 after another. There are ways how to create multi dimensional virtual addresses by. Usually we are also working with one-dimensional addresses because it's simpler. It's easier. The tricky part is how to ensure that this translation mechanism is effective and efficient. So first effective. It needs to really translate all the addresses properly so that each process is shielded from all other processes. That's difficult on its own. And second, it needs to be damn good efficient, because if it isn't, then it will slow down all the computations significantly. So the CPU needs to be doing this transparently and very, very efficiently. And one of the most important parts here from the perspective of operating systems is that sometimes this translation, this mapping may not exist sometimes because it's a mistake. If you are trying to access memory which wasn't previously allocated, that's something you may have already encountered in your Arduino classes. So if you are trying to access memory where you shouldn't be, so you have a wrong pointer by accident or by a bug in your code, it's a fault. And this fault will result into termination of your application. The operating system will kill you, your application to be exact. OK, so the this is what happens and this is handled on the hardware level as an exception. So if this mapping doesn't exist, the CPU raises an exception. This exception goes into some exception handler which is a part of the operating system. This is code provided by the operating system, and this exception handler needs to decide what's to be done with this exception. If it's a mistake or if the operating system thing it's a mistake, then this exception will translate into on Linux into signal 11, which is 6F. If you heard of it, you may have noticed it. You may have encountered it in the record X. That's what happens if you are doing something bad with memory. So 6F will terminate effectively and effectively your application. Sometimes it also may be used to some trickery. For instance, if you allocate huge amount of memory, you allocate TB of memory, then Linux says, no problem, here's a TB of memory. But it's a trick. It's a, it's a ruse. If you try to access the memory, then it will slowly associate the memory with real physical memory. So it's like it's something like a credit card in a bank, right? You theoretically have this huge amount of money on the credit card, but in the end, if you try to draw the money, then we will have to pay the bill. So it's the same thing. You will get the virtual memory. So you will get the illusion that you got the memory, but the memory, the physical memory will be allocated later as you try to access the memory. So basically every time you try to access a new part of this allocated memory, new exception will will rise and the operating systems will say, OK, this is not a, it's not a mistake. I actually promised this memory to this application. So now it's time to make good on my end. And I will just allocate physical memory for it and and create recreate this mapping and then restart this instruction so it will properly execute without without exception, without fault. OK, so this is like a basic mechanism, the most important mechanism which is there, which you really need to know from the beginning. Yeah, I forget about this. This is the new meme. I haven't, I haven't showed you yet, Right? So as an example, make sure that everybody understand that because the previous slide was all letters and I was just waving my hands. So just let's reabsorb it on a real example with a real picture. So this is a virtual address of the process. You already recognize that this is the picture I took from the some of the previous classes when we talk about how data are organized within a process. So there is a segment where the code is some constant, some data heap, etcetera. So each part has some proper location in the virtual address space, usually starting from zero. And the memory unit, the memory management unit of the CPU uses some instruction, uses some data, some mapping which was provided by the operating system to translate all the virtual addresses into physical addresses. So every time the data are accessed, a constant is loaded from this address. This transparently happens within the CPU. So actually this part of memory, physical memory is accessed right and returned as the constant. Furthermore, all these addresses are handle it in the hardware. So everything what happens in hardware like caching also works with physical addresses. So L1L, 2L3 caches all work with physical addresses. Why we are doing this? Well, some reasons I've already told you. The most important reason, the one I should probably start with is security. We need to provide the illusion for each process that it's that the whole system is its own, that the whole memory is its own. Well, actually we are technically doing the same thing with CPU using time Multiplex, right? We are giving the illusion that the process is alone on the CPU, but actually we are taking it off the CPU once in a while to allow other processes run well. With the memory, it's more difficult because we cannot use time multiplexed with memory easily. So we are dividing the physical memory into multiple virtual spaces, making sure that each virtual space has its own physical memory. One of the reasons, one of the other reasons is it was used in the past. We can create an illusion that we are having a huge enormous memory space, petabytes of memory right in 64 bit addressing. Yeah, it's an illusion because physically normally you can have up to TB easily if you have enough money, several terabytes, perhaps more is much more difficult. So the physical address space, the virtual address space is much larger than the physical address space. Actually, nowadays it's it can go the other way around, because if you have a 32 bit system like AI, 3232 bit implies 32 bit pointers. So if you have only 32 bit pointers, your virtual address space is limited to 4 gigabytes of memory, which is not much by today's standards. So it's very easy to create a machine on the 32 bit architecture or 32 bit application which can use only four gigabytes of memory. But technically the host may have much more. My laptop has much more than 4 gigabytes, so no problem today. So this is no longer primary reason because usually you are not using petabytes of memory and usually you are satisfied with the amounts you can get. And also thanks to the virtualization of this mapping. Thanks to this concept we can create additional features easily. One of them is memory mapping. Create a memory mapping of a file is very easy. You just promise that some data of a file will appear somewhere in your virtual address space. So again, the operating system just remembers that when anybody asks for this data, it needs to be loaded from this file. So the loads themselves are performed using this handler, using the exception. So whenever anybody tries to access the data promised by the memory mapping, the data will be provided on demand, on demand by and handled by these exceptions. Another thing is we can use it to data sharing. We can share data among multiple processes. Actually that happens all the time because there are plenty of data in this area which are the same for multiple processes. Because we have libraries. We have low level libraries, operating system libraries, pieces of kernel that needs to be there in every application. And it will be very wasteful if we need to load these libraries every time any application wants that. For instance, the Lib C library. It's not that big, but it's not that small and you are running thousands of processes on your own Linux server. If the Lib C needs to be replicated 1000 times in the memory it would be very wasteful. But we don't have to do that, We just need to map it properly so it's loaded once in the physical memory and every process gets like a virtual copy of that only using this memory mapping mechanism. OK, important concepts. Sorry skipped 111 other sentence how to do this. This was why. So we are now we are switching to how and there are two possibilities how to create this mapping principle. The older and I'd say more clumsy way how to do that is segmentation. Segmentation is no longer being used in current systems, but it's a good place to start because you can see how to do it more easily. So the concept is that the virtual address, the virtual space is divided into logical segments. So some like blocks. This was originally designed to go 1 to 1 to the concept of work of the division of the process space, because you have one segment for code, another segment for constants, another segment for heap. So you have different parts of your application that needs usually needs separate handling. For instance, the code needs to be read and executed, right? The data needs to be written and not executed, etcetera. And the trouble is that you don't have, you don't know how large the code segment will be, how large the data segment will be, how large the heap segment will be. So you need to make this segment adjustable. Each segment may have its own size. That's the main concept of segmenting. So each segment have a different size. And of course these segments have some identification, for instance, an ID index number. So finally the address has two parts, the segment ID, segment number and segment offset, which is how many bytes from the beginning of the segment the data are. So basically each segment creates kind of a small virtual subspace of its own. Because if you fixed the segment number, then by moving by changing the offset, you can move only within this segment. If you have fixed segment number for the code segment, you can only access the data. You can only access the instructions in the code segment. If you fix it for the heap, you can only access the data on the heap and the translation is provided via something called something which is called segment table. It's really like a translation table in memory where all the descriptors of all segments are located and each descriptor provides a base pointer to the physical memory. So it provides a base plate for the translation and some additional information, for instance, the length of the the size of the segment. That's that's important. And also perhaps some additional attributes like whether the segment should be readable, writable, executable, etc. And something which is called a segment fault. And by the way, this is a term which we are retaining today, even though we are not using any segments anymore within our CPUs because segmentation has been deprecated, it's no longer used. But still we keep the name segmentation fault, segment fault when we cannot access the data within appropriate within some segment. So if the translation or the validation of these access rights or something fails, then we get this segment fault. How this works? So we take the virtual address, it has segment part and offset Part 2 parts. 2 dimensional segment part is basically an index to this table. So it's an index of the segment descriptor which is a structure I record in this table. So we read this record and we need at least two important information from base physical address pointer. So we take a base address. This is the beginning of the segment within the physical memory and we need some limitations. So we need to remember the length of the segment. And the translation is basically an addition. We just take this pointer and the offset, we add them together and that's our desired physical address over here. Because the offset from the beginning in the virtual address space is the same as the offset in the physical address space. That's the amount of byte we are shifting. It's it's easy. Of course we need to perform some additional checks. For instance, we need to perform a check that the offset is smaller than the length. Otherwise we can end up in a completely different segment and that would be disastrous. So there need to be some additional check that the length is smaller, that the length is greater than the offset. So that's how this translation works. Is it clear? OK, so as you can see it's not very practical because every access to memory will result in two reading this data structure, and even if this data structure were cached somewhere, so we still need to take this base pointer and perform an add operation. Add is not that fast, so each memory access instruction results in at least one add and one comparison. So we need to compare offset with the length these are. These two operations cannot be skipped. By the way, do you know how comparison is implemented? What is comparison technically? Subtraction, which is addition. So we're performing 2 additions technically with with some small modifications within the processor. That's right. That's why segmentation is not that practical. And there are, sorry. There are a few more additional issues. One of them is the different sizes of different segments create fragmentation within the physical memory. Imagine that you want to enlarge the heap. You need to reallocate the heap because heap is growing and you need to reallocate it. You need to enlarge in it. But heap is hitting this barrier. Yeah, you can. You can easily change the length as long as these two rectangles don't overlap, right? So we can increase the size of the heap slightly, but once it reaches the border of the constants segment, we are out of luck. Well, actually not not entirely. We can shuffle these, we can move these segments no problem, but it's tedious, clumsy and slow. So yeah, we can deal with fragmentation, but at heavy costs, so it's very impractical. This is why another concept was created called paging. Paging goes with a different direction than. The main difference is that the paging uses pages and frames, so some data blocks of equal size. So they have some predefined size, which has to be not maybe, but has to be power of two. Yeah, power of two. And both virtual and physical address space is divided into these blocks of the same size. That's like a must that does the main, main thing you need to need to remember. And yeah, just for technical notion, the virtual address space blocks are named pages and the physical address space blocks are named frames. But that's just to distinguish whether we are talking about virtual address space or physical address space because they have equal size. So one page fits exactly 1 frame exactly. And the virtual address space is now 1 dimensional. We have just one address. Because thanks to this condition, we can easily chop off the offset. We know what offset part is. We know in which block. We can easily take the index of the page just by cropping the proper amount of bits from the beginning of the pointer. Or we can take the offset part just by cropping this amount of bits, the end amount of bits from the beginning from the end of the pointer. So we we don't make this distinction in the virtual address space. We just use one linear number. And where exactly is the border between offset and the page number? That is no concern of programmer. Programmer doesn't care, all the pointers are the same. OK, now we need a mechanism to translate virtual address into physical addresses when we have this concept. So this translation mechanism is usually called page table. Well, the simplest mechanism is called page table. And again page table is a translation data structure where we have a for each page, we have a, a offset, we have a, no, sorry, we have a base pointer to the physical memory. So again it's indexed by page number. Similarly, like the segment table was indexed by segments, and each entry contains A-frame number and possibly some attributes, again, like attributes like whether the memory is readable, writable, et cetera. Whether the translation is valid. That's also a good flag that should be there. And that's pretty much it. By the way, this table is usually designed so that each entry has the exact amount of bits as the the address size. So if we have a 64 bit addressing, each entry in this page table has 64 bits, where the hell we find the extra place for these attributes? Actually, this is a trick question which aims to test whether you followed all this information properly. That's it. If we know this, there is one peculiarity about pointers stored in this page table. Physical address pointers stored in this page table. What is it? Well, we know that all the frames have the size. So if we know that every frame has a size which is power of 2, what will What will happen if we try to write this address down in bits? Read it in a binary nobody? Well, this implies that each page and each frame starts at address which is divisible by this. No, this so far, so clear. OK, so this this part is clear. So if the address is divisible by a power of two 2 to the power of N 2, Yeah, exactly. The last N bits will be 0. That's what LIMN is about, right? So the last N bits will be 0. So if you're storing the address into this table, then we have all the 0 bits at our disposal. We don't need them. We know they're zero, so we can reclaim them for other purposes. So there will be at least N lower bits in this entry, free to use for other purposes, for other flags, for instance. OK, so let me let me go again step by step how this translation works. So we have a virtual address, it's linear from our from the programmer's perspective. But during the translation, we need to split it in two parts. And we are splitting it at the bit level because we know that N minus and N lower bits belong to the offset. It's this division can be done on the linear number just by chopping off the lower end bits. Easy peasy. And the remaining bits, that's the index to the page. That's the index of the page. So that's the index to the page table, right? So this value P basically you can take this address and shift it by N to the right and you got the index. Right, but technically shift isn't a mathematical operation. Shift is that you just take the bits. If this is a constant, then it's not a mathematical operation. You just take the bits and send them over a different set of wires. You don't have to perform any mathematical operation, unlike adding. So technically you just take the upper bits to index a position in this table, and you take the lower bits and put them aside. Here in this table, you read the upper n -, n bits and take them as an address to the physical memory. And you append, you override the lower end bits with the offset you stored here. So again, there is no mathematical operation. You just take these bits and copy them over here, just send them over a different set of wires. That's it. And this is the physical address. Voila, no additional operations. So it's much faster than adding. There is no adding. There's no math involved. You're just sending the data. Only thing that is involved here is you need to access the memory in this table and read this value from this from this table. Yeah, you need to perform that. And of course, if there are some significant bits in the lower part which indicate whether the memory can be accessed, whether the record is valid, whether it can be read, executed, whatever you're doing with the memory right now, yeah, then additional operation needs to be performed there. But usually this operation will involve checking single bits. So it's easy. It's easy for the hardware and the CPU to implement how this page table will look like. OK, so basically if you want to cover the entire virtual address space for every page in the virtual address space, and there are plenty of them, you will need to create an entry within this page table. So each entry will keep the address. Some of these entries may be empty. There is some flex saying this is just an empty space. We are not using this page at this moment. Some of them have valid addresses. So this page #14 refers to the page table entry #14 there is mapping one to one. Page 14 goes to the entry 14 and there is number 456, which is an address, physical address, which points to the frame 456 in the physical memory. So this is how the translation works. And yeah, some of this, some of this are not or explicitly marked as as invalid. So when somebody tries to access this page on this frame, it will blow up in his face because the CPU will arise an exception. And then this exception, this page fault will be handled by the will be handled by the operating system. So again, this might be a bug. So the operating system will kill the application or it might be intentional because the the operating system is doing some magic behind like loading data from memory mapped file, swapping the data to the to the hard drive, providing the allocated memory on demand or something like that. OK, a few things we need to spill out and I think yeah, we will do these two slides and we will conclude for today. So few more things you need to be we need to spill, spill out right away. So we yeah, you probably don't you might have already noticed them, but let me go through them one by one because this is like a difficult stuff for many people. So first of all, let's say I have this one level page table you you just seen on the on the previous slides, this one. And I have a 32 bit address space, both virtual address space and physical address space to be on the simplest side. And I have 4 KB pages, which is kind of a common size 4 pages. Normally we are using like 4 KB pages. Some architectures use different sizes. On IA 32 you can use 4 KB or 4 megabyte pages. So it's it's a normal size. So we have 12 bits per page per offset, right? 2 to the power of 12 is 4 kilobytes everybody. I I didn't for the time purposes, I didn't ask you that, but I believe everybody sees that. So what is the size of the page table entry 11 this. What is the size of this box in bytes, bits, whatever? I'm waiting. I'm not going to make this easy on you, right? You got all the information you need. You have 32 bit addresses in virtual space, 32 bit addresses in physical space. Everything is 32 bits. And we have 4 cool pages, so each page requires 12 bits for offset. Just to be clear, OK, if I have this page table, how many bits, how many bytes or whatever I need to allocate for each entry, what does this entry hold? What is within this box? Yes, I'm very glad for that. At least somebody's paying attention. So thanks for that. Just please give a bit more time to the rest of the class. I don't want to dampen your spirit. I just want everybody to realize that it's a physical address. Did you catch that? OK, so who catch that can answer me the question. How many bytes or bits or whatever? What will be the size of one entry in this table of one of these boxes? It's one physical address. So what is the size of physical address? 32 bits, That's right. Actually I can, I can drop the lower 12 bits because there will be zeros. So technically I can go up, go with 20 bits, but it's very impractical because 20 bits is that's not a very good number. So usually we will go still with 32 bits, we will just recycle these 12 bits, 4 flags and other stuff. But yeah, one entry is 32 bits, 4 bytes. So we are moving. So what's the size of the whole table? How many entries are there in the whole table? OK, I will, I will go easy on you. How many entries are there? You can read How many entries are there? I'm not sure how you get to that #128 I understand that perhaps you don't see the detail because it's written in small numbers. So you can apply whatever zooming device you have, or you can read the slides from your laptops or whatever, but you will you should be able to deduce it on your own. What is the large N? Yeah, I realized that I have two NS here. So what is the large N? There is a large N and small NI realized we are on this for 2 1/2 hours already and yeah, I'm exhausted as well, but bear with me. Bear with me. Just keep it to one more slide after that and we'll we're done for today. Master some, some lasts, emergency results and some power to your brains. What was the last what? What is the large N here? This is the size of the address. This is the number of the size of the offset, the number of bits in the offset. So I'm relying on you, nobody else. Volume up. Thank you very much. It's 32 bits for the big N and 12 for the for the small 1. So can you, can you please finalise it with this hint? So it's N to the power, 2 to the power of large N minus small N 22 to the power of 20 is roughly million. Yeah, it's like a mega, roughly 1,000,000. So we have 1,000,000 entries in here. So what is the size of this table? You just need to multiply it with the entry size. That's it. Someone from this side of the audience please. I haven't heard anything from this part. We have 1,000,001 mega to be precise, 2 to the power of 20, 4 million. That's right. 4 mega, 4 megabytes actually of memory we need for this page table. So it's large, it's huge, not that huge, it's affordable, but it's quite large for managing 4 gigabytes of memory, right? And the most important part is we don't need it all for normal applications. If you run an application that consumes fewer megabytes of memory, that's for a simple command line tool, that's more than enough, then you will allocate another 4 megabytes just to keep this page table. That's a lot. So what can we do with that? We can go we can go into two level 2 level indexing. So basically we split the table into, we split the address into half. Well we can split it into multiple chunks, but in this case half would be perfect. So it so happens that with four KB pages, half of this of this page table index is perfect. If this is 20 bytes, then 1/2 is 20 divide by divided by two is 2 10. Thank you. So trying trying to reach out with basic arithmetics. So we divide it into 10 bits and 10 bits and still the offset remains 12 bits as it as it was before. OK, so because we still have 4 KB pages, so the offset doesn't change, we're just splitting the index of the page. That's it. And so it so happens that once the index is only 10 bits, we don't need MB of entries, or 4 megabyte mega of entries, 4 megabytes of entries. We need only 1K of entry, so 4 kilobytes of entries, right? But then again we need 2 levels because we need the same for the second level. So basically the first level will hold the pointers to the second level page tables. It's like you are splitting up an array into two level tree structure. The first node is only one and it will be always there and there will be up to 1024 second level nodes. And it so happens that these tables are 4 kilobytes long, so they will fit perfectly into our pages. That's just a coincidence, but actually it's a happy 1. So technically we are allocating pages for these tables. This page needs to be always in the memory and we need some beginning point, some starting pointer where the root is. And this pointer is actually stored in some special hidden register of the CPU. So there is some system register that cannot be accessed by regular applications, only by the operating system, where the operating system sets the pointer to the first level of the page tables the physical address, right? This holds physical address of this second level page table where the second index is applied. And finally, here is the address of our final page table where the actual data are. So we apply offset to it and we can read or write the data over here. What's the benefit of this? The main benefit is that not all these tables are there. This table needs to be there all the time, but we can save a lot of memory because many of these tables may be missing, may not be there simply, and if they are not there, we are saving memory. So if we have a very small application, we can allocate only a few of these second level page tables. So we allocate only a few pages to manage the whole translation process. I will quickly go through this again next week because this is something worth remembering. Just a few more notions. You probably notice that each translation of the memory requires several accesses to memory as well, which is very, very unfortunate. So what happens here is that CPUs usually employ additional caches. They have special names, TLB translation, Lucaside buffers, and this is a very specific cache designed only for memory translation. So this cache is like regular caches associated, but it's very small, usually like 10s or up to 100 entries, something like that. And it has, it only provides translation between virtual addresses or page tables, page page addresses to physical addresses. So it's like a very special cache which can be accessed very fast. So not always we need to perform this entire entire lookup, but this lookup is performed only once for every page that's being accessed. And then the address is stored into this cache. So next time you're accessing data on this page, it's quickly resolved through the cache. It doesn't have to go through the entire lookup process again. That's the point. And by the way, some, some processors like MIPS, which you already seen use something which is called zero level page tables, which means it has only the TLB. So it only uses this cache and the operating system can insert entries into this cache manually. So it's like another way how to deal with memory translation. OK, sorry, I'm I'm slightly over the expected amount of time. Are there any questions for this, for today, for this topic before we conclude for today? I hope next week we'll be roughly on the same schedule. So we will again have the extended lecture, but I hope we will manage to do it somewhere within this amount of time, so roughly around six. We hopefully conclude any questions for today? I suggest next week at the end, if time permits, I would like to dedicate a few minutes 1st to go through the testing process to give you some glimpses about how the example look like. We will go through some sample sample tests cases, sample test questions. And also it would be a good idea to, let's say, go through the entire course before attending tomorrow, next week's class. And if you have any specific questions regarding any topic we covered during the the semester, then it will be a good time to pose these questions. So I'm not pushing anyone, but it might not be a bad idea to just rehearse everything, refresh your memory or go through the slides before next lecture. So if you have any questions, you can easily ask them during the session. Thank you for your attendance for today and hopefully see you next week.