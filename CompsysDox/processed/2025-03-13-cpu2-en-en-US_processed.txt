Today we're on time, so we are getting better and I believe we stopped about here in the middle of the CPU course last week. So let me just continue from here on. Last week I introduced you the registers and as an example, I use the X86 architecture, which is one of the most profound architectures because we have most likely you have it in your laptops. But also it's an example of a not very well designed architecture. And the reason for that is it's quite, quite ancient because it was designed many decades ago and back then they didn't realize in the modern times we will need so many registers. Let me give you an example of an opposite architecture which has too many registers in my opinion, and that's IA 64. By the way, the X86 architecture or the architecture to which I usually refer as as X86 is officially called IA 32. So IA 64 isn't just an ext 64 bit extension of IA 32. It's a completely different architecture which was designed by HP, not by Intel. And yeah, I can realize this, this illustration might be confusing. So let me just give you a glimpse what's what's where. So here the first part, first block is called general registers. So they have 128 general registers. So registers that can be used for whatever at arithmetic operations you'd like using integers. Aside of that there is 128 floating point registers. So registers dedicated only to floating point operation. And aside of that there are also application registers. So registers which are dedicated to special functions like holding the instruction pointer or holding the stack pointer, etcetera. So as you can see they have registers in abundance. Besides these more traditional registers, because you can still imagine what general register or floating point register would hold, there are additional registers like predicates. Predicates are essentially single bit registers. So there are registers which each can hold a single bit and they are used in instructions that require some sort of condition. So these instructions kind of refer to a predicate register. And if the predicate register holds 1, the instruction gets executed and if they hold 0, the instruction is skipped. So this is a very complex architecture and besides that they have a branch registers where an address of a branching instruction can be stored. So if you need branching, if you need jumps, then they have dedicated registers for addresses for branching. So as you can see you can get a very simple or very narrow or narrow minded architecture like X86 and you can have a very broad architecture that uses splint horror of registers like IA 64. Most of the time in this class, actually this refers mainly to this lesson. We will use the MIPS architecture which stands somewhere in between. It's not very fancy in in its old design and everything, but the MIPS architecture actually became basis for RISC 5 architecture. I told you about that last week I believe. And RISC 5 is something that is quite modern today there are many companies that trying to build their own RISC 5 CPUs and maybe in the foreseeable future RISC 5 will play a significant part in our daily life. So it's not like we are teaching you something ancient, something archaic. This might be useful for you as well. By the way, the one of the subjects that's pick up on the discontinuation of this subject, architecture of architectures of microprocessors I believe it's called, uses RISC 5 as the referential architecture on which they teach you more in more detail how the CPUs behave. So it it's a good a good thing that we start with MIPS, because you can easily pick up with RISC 5 afterwards from the terms of registers. In the terms of registers, MIPS stands somewhere in between X86 and IA 64, maybe slightly on the X86 side, they have 32 bit 32, they have 3232 bit registers, so it's easier to member. It's MIT 32 which has 3232 bit registers, easy. And these registers are like general, they are designated R0 to R31. So it's, again, it's very easy to remember. You don't have to remember that there are some special registers. Actually that's not entirely true. I will get to that in short order. Yeah, sorry. Yeah, yeah, sure. So what's in there? It's quite simple architecture in the terms that, for instance, there is no stack. Well, what? What does it mean? Because you need stack, right? Everybody who knows something about programming realises that you need stack because without stack you cannot perform function calls, right? Because where would all the local variables go besides the stack? That that's not entirely true. This says that the ISA specification itself doesn't define how stack should be implemented. So the stack isn't part of the CPU specification like in X86. Unlike in X86 where you have stack register as an explicit register, you have specific instructions to push and pop this stack register. So this architecture says, OK, implement the stack as you wish. I don't care. I I just give you the registers. I just give you branching instruction and everything. But it's your job to implement the stack. There are no flags. Yeah, again, this is not not big deal. No big deal actually, because you don't need that much flags. You can have specialized registers for that. So no big deal. And yeah, the instruction pointer or the program counter, of course, has to have a separate register. So this is The only exception to this. So besides the regular 32 registers, you have one extra where the instruction pointer or the program counter is. So it's it's basically very simple. Let's let's dig into it. But before we do that, there is one piece of information I need to give you right away before we get started, because this is going to get somewhat intermingled with the ISA specification. You know, as I said just on the previous slide, the ISA of MIPS give you no stack. There is no stack, but we need stack. Stacks are good. We really need stack to implement software, otherwise we couldn't do things like function calls. So we need additional specifications which told us how to implement stack and why. This needs to be a specification, because if you invent your own way how to implement stack and you could, your software wouldn't be compatible with other software, like with libraries, with operating system, etcetera. And it's a very good idea that all the software that runs in one system is somehow compatible at least on some level. So they can. For instance, you can for instance call function calls of a library and the library knows how the items are stored on the stack. So the library and your application creates the stack in the very much same manner. And to do that you need additional specification. And the specification is called ABI Application Binary Interface. You are at this point, you are probably familiar with API, right? Does anybody hurt the acronym APII believe so. Yeah, that's pretty much it. So API is an interface at the application level, at the programming level, at the level of your code. This is an interface that needs to be specified 1 storage beneath you, one storage beneath regular programming. So this is an interface that needs to be obliged by the libraries, by the compilers, by the operating system, so that the applications are designed in a particular way and so they can communicate with each other. Most importantly, how the registers are being used, especially when one module, one piece of application calls another piece of application. How stack is implemented? That was my my original thought and also function call convention. So if you call a function in a library, how and where you store your function arguments and vice versa, how and where you will find the result of the function. That's very important because otherwise you cannot call foreign libraries. OK, so in this case I'm going to intermingle in some parts the ABI specification with the ESA specification. That's the specific I told you last week. That's the specification of the interface of the CPU. It tells you which which registers the CPU has. It tells you which instructions the CPU has. So sorry, I just got interrupted and I lost my stack. So basically the ABI, that's what I wanted to finish is a like a prescription, like a recommendation how the CPU should be used. You can, you might have multiple Abis, but it's not a good idea to follow, follow multiple Abis. So usually you have one. So now if we know that we have 32 registers in the ABI, they have specific meanings, so they are somewhat like named. And there is a prescribed way how you should use the registers. For instance, the first register, actually the zeroth register, it's called 0, easy to remember and it holds zero that's also easy to remember. Why would we need a register that always holds zero? Well, for one, if you need a zero to read from, if you need to read a zero from somewhere, you you can read it from the zero register. That's, that's quite useful. If you need to compare something to 0 and it's quite a usual task in in a branching and in conditions, then you have a zero register. So you have always a zero there. It seems like a waste, but it's actually quite useful. And the first register is a assembly temporary, which means if you have a temporary value, if you're making some computations and you need to place a temporary value somewhere, the first register is the the first one you should. You should put. You should use for that. These registers are used for function calls V0 and V2 is used for a return value. So if you have a function call and the result of the function is 64 bits at most because there are 232 bit registers, then the result result is placed here. Otherwise it needs to be placed on the stack. Why don't we place the the result on the stack all the time? Why do we bother returning values via registers? It it's just a complication, right? Because you need to remember that these two explicit registers are used for returning values from function calls. Why would we bother if we have if we have the stack anyways? Well, you can get it synchronously via memory. That's that's the same thing if you write it to the memory. You can read it from the memory. That's the same thing. If you write it, it's much faster. That's right, because writing to the memory and reading from the memory it's quite slow, even even with caches. So returning the value or values through the registers is much much faster, because just writing something to the register or reading something from the register happens on the synchronous clock basis. It's not something like you should wait for. If you write something to the memory and then read it back it, it might take several cycles or 10s of cycles even if it's cached in L1. The same goes for function arguments. These 4 registers are dedicated to function arguments. So if a function has less than 4 arguments and they are less than 32 bits each less or equal, then they are placed in these registers again for speed. If they don't fit or the remaining there are more than 4 arguments, they are placed on the stack. Yeah, temporaries are used like the assemble. Temporary temporaries are used for immediate values. That's you need to place somewhere during your computation so the compiler allocates them dynamically for local variables or for intermediate values. Safe temporaries have similar meaning, but the difference is Here I haven't mentioned the last column yet, the preserved column, which tells us whether these registers should be preserved or not during a function call. That's another mind tweezer, because sometimes if you make a function call, the function needs to use registers. Well, not sometimes. Usually because there there is another code. The codes need to compute something. So if you make a function call, it's possible that some of your registers as as you as a function will be overwritten by the call code function. OK, so in this case, this flag tells you whether the callee, the function you are calling, is responsible for preserving the registers. And these are special because they say yes. So if a function is called, the callee, the function that's being called is responsible for either not touching these registers at all, so not modifying them, or saving them somewhere in the memory, for instance, and then restoring them later before the function concludes. Actually, it's not the callee itself, it's the it's part of the of the function invocation protocol. But basically that's that's what compiler or the runtime must ensure if these registers are being used. Yeah, temporaries are obvious. There are also some kernel registers which regular application shouldn't use. They are special registers dedicated to kernel. Well, as we get to it later, a CPU has a special mode, a special function which is called an interrupt. Sometimes the regular run of the application code can be interrupted by an external source, and at that point the kernel is invoked. And it's a good idea that the kernel has immediately a few registers it can use without being concerned whether these registers are free to use or not. So these registers are dedicated for kernel use only and the last four are quite important. This is a global pointer. So if you have a global variables in your code then all the variables are stored in a particular location and this is like a base pointer for them. So this is like a pointer at the beginning of the area where all your global variables are stored. Do you know what global variables are? I hope after a few lessons of Arduino you already have so same goes with the stack pointer. On the stack we have stored the local variables and possibly extra arguments if they don't fit here. So stack pointer is here. So you can use the stack pointer to address add extra arguments or the local variables of the function frame pointer. It's slightly complicated. At this point I will just tell you that the frame pointer goes along with the stack pointer. There is a particle place on the stack you need to also locate. That's not very important right now. I will talk about that later when we examine the function call protocols in detail. So these two work together, stack pointer and frame pointer. And finally the return address. Oh, that's a very special register because if you make a function call, this is a very special register in the way that the instruction that performs the function call will actually use this register to store the previous value of the program counter. So basically if you're making a function call, first the program counter is like snapshotted here, so it's like saved here. And then the jump, actually the function call is basically a jump will will take place. So the jump itself is preceded with saving the original address. So the callee, the function which is being called, can take this address and perhaps store it somewhere, perhaps store it on the stack or or just otherwise preserve it. And when times come to return from the function, this address is used to jump back from where we were called. OK, that's very important, because otherwise the jump that takes place during the call wouldn't know where to return. You need an address where you need to. You need to know to which address you want to return after the function is finalized, after the function concludes. OK, I will now go through a few examples of MIPS instructions. I'm not doing a complete reference manual reading here, so I won't be presenting all the instructions that are available. Just to give you some glimpses, some some notions which instructions are available, which instructions are like typical for this kind of architecture and how they are constructed. It's not important that you exactly remember which instruction is which, meaning ADD and ADI. This is this one is easy because ADD actually isn't an acronym, it's a name. This is a addition so that it's performing ADD operation, and this is ADD immediate, so it performs addition with a register and an immediate value. But you don't have to remember this. For the test, we will give you the name of the instruction, but you need to somehow remember or at least deduce the semantics of the instruction because we will. It will be required of you that you translate instructions into C code or vice versa. So you need to understand the instructions at least at the semantic level. You don't need to remember all the acronyms. So the semantics of the operands, remember there are three operands in this architecture, so the semantics is the same as if you write them sequentially one after another in AC expression. So in AC expression you would have the right side, the left side, sorry. So that's the target, that's where the result will be stored. Then you place a virtual equal virtual assignment between these two. And then the name of the operation is placed virtually between these two. So semantically, this is the equivalent of into the register Rd. like a destination. Let's play Rs like the source and RT that's just the next letter after S so that's another source. So these two source registers are added together and stored in this, in this target, in this destination register. So the semantics is actually easy. Just remember that the equally the assignment goes here and the operation goes here and that's it. Just read it as if it's written in C The add immediate is very much the same. The only difference is that the second, the third, sorry, the last argument, the last operand isn't a register value, isn't a register index, it's an immediate value. So there are 16 bit. Remember the the layout of the instruction, there are 16 bits reserved in the second-half of the instruction work, so these 16 bits are extended. Yeah, the tricky part is that this register is a 32 bit register and this value is 16 bit value. So we need to make them somehow compatible. That doesn't happen magically that we need a specific way how this happens. So this operation here sine X is a signed extension from 16 bits to the target size, which is 32 bits. And what's signed extension means? Well, regular extension just simply place zeros at the beginning. So if I have like let's just say something like 1011, let let me just write 4 bits for you. Let's imagine what's extension of four bits into 8 bits so I don't have to write 32 bit numbers. So if I want to extend this in a regular normal way, unsigned way, then I will simply add zeros. But this doesn't work properly for signed numbers, right? If this was an unsigned number then everything is fine because if this was an unsigned number then I'm just adding zeros. So this is the same notation in a in eight bits as this was in four bits. However, for the side number that's not true because we are using the two complement for the side numbers and this number was starting with one, which means in A2 complement if this was a four bit number in two complement. Note it was negative exactly. So when it's negative, I have to extend it in a way it will remain the same negative value in the extended format. Fortunately for us, it's very simple. We just take the highest bit and copy it. So the sign extension means I I'm not putting zeros here, I'm taking whatever the highest bit is and fill it here. So in this case it would be 11111011. OK, if you don't believe me, small home exercise would be to verify that this is true. Just you can use a calculator or whatever converts bit values into into the similar values or whatever base you prefer, OK? The same goes for sub. Sub is subtraction, so I'm not going to dwell on that. So this is addition, this is subtraction, this is obvious operation. And these are obviously just how to read this properly. These are like placeholders. isn't a name of an exact exact register. It's a placeholder. And you can use whatever register from the zero to 31. You seem fit. So an example would be add R2 equals R4 plus R5. OK, yeah, maybe this is obvious. I'm just want to point it out for for those who might be slightly confused with the notation, okay, example and comparison of the MIPS architecture to X86 architecture. Yeah, we are doing that for several reasons. One reason is that my esteemed colleague, Mr. yes, probably still teaches or hopefully I think you've verified that at the beginning of the semester still teaches X86, still use this X86 example. So you probably at least a tiny bit familiar with that particular notation. And 2nd, sometimes it's just it stands out how this how this notation is slightly more verbose. The the reason is that you have only two operands in X86. So in some operations are more slightly more tricky if you have only two operands per instruction instead of three. So the first example, let me give you an addition of two values into the first one. Well, that that's easy because if the target register and the first register are the same. So basically we are adding T0 into T1, OK, easy. So that that's the the same goes in in X86, because in X86 you cannot take two registers and put them in the third. You are adding one register into another register. That's the notation. So you are adding ebx into EAX. However, if you want to do something more elaborate like this, yeah sorry, like this, if you use different registers that the T2 is the target, T0 and T1 are the sources, then in X8X it will split into two instructions because first you need to take the first register and put it into the second one. This is the move operation. It just overwrites EAX with EBX and here you add the second register into the first one. So basically instead of 1 instructions, you need 2 instructions. Finally increment this very trivial, very common operation. If you have a traditional for loop then usually you are incrementing a register somewhere inside the for loop typically. So this would be the increment in emips. In X86, yeah, you can still do the same thing, so you can do add one. But also X86 has this special instruction increment. And I think if you incremented EAX, I'm not entirely sure. Now it has some very, very short code, so I'm not sure if it's one byte or two bytes, but it's very short if you're incrementing EAX. Or maybe it's very short for ECX. I'm sorry, I don't remember that one, but that's not important. So they have a specific instruction for increment a logical operations. Yeah, I'm not going into the details because you already know and orcs or and negative or. What's that? Why do Why do you have we have negative or? Well, it's easy because it's more useful than have a simple negation. If you want to emulate a regular unary negation but bitwise negation so each bit in the word is flipped basically, then you can use the negative or, right? You just need to write the source register twice. Well, this nor is a or operation which is negated afterwards. So if you take a value a any bit, this holds for any bit value a or value a. It's a right? Because if this is 1 and this is 1, then one or one is 1. If this is 0, then this is zero and zero or zero is 0, so applying or on the same value has no effect, right? But this is negative or, so the result is negated afterwards. So basically not a or a is not A and voila, we can simulate not operation using the NOR operation. So they have decided not to put there an extra instruction, an extra up code if you can do the same thing with the OR instruction. Yeah, a slight concern might be that this like performs additional operation, right? Because you need to perform the OR operation before you flip the bits technically. Well, as I said, technically, technically it's true. First of all, the hardware might detect it. So technically hardware can use optimizations that prevent that. So hardware can know that it's the OR is taking place on the two identical registers. So we'd like skip the OR part and just go with the NOT part with the negation. And 2nd, it's more beneficial to reduce the scope of the instruction set, so not put extra instructions that are really not necessary. So in this case they go with nor instead of having extra not the same. The analogy of these instructions which work which work on three registers is here and I or I and X or I is like in the addition or subtraction it's it takes 2 registers, the target register, source register and an immediate value. The difference here is that we are using the zero extension. The zero extension is like for unsigned numbers. We we always fill it with the zeros from the left instead of taking into account the the sign of the of the value. So the values here, the immediate values here are treated as unsigned values, which is much more sound for bitwise operations. For addition and subtraction you probably want both a positive and negative values, so it makes sense to have a signed immediate value. For bitwise operation it doesn't make that much sense, so it's easier. It's better to have unsigned operation here. Yeah, bitwise shifts are extra easy. So this is, these are just the names you get the register, the target register, source register, and this is an immediate value. This is a very awkward acronym. It's the shift amount and it says how many bits the number is shifted to the left or to the right. In shift operations, the shift is the result is just scropped. So if you have any extra bits on the left or on the right which overflows the register, they are just thrown away. However, you have also analogy to these two SRASRAA rotation, which is like a arithmetic shift. So it keeps the sign. If you're rotating, it tries to maintain the sign. So it's like a more like a division or sorry, this is this RA to the right. So it's like a multiplication by two. Yeah, that's right, sorry. Right division by two. So this is like a division by two which preserves the sign. Doing that to the with the left shift doesn't make sense because if the sign is basically the highest bit, then any shift to the left will throw away the sign anyway, right? But if you're shifting to the right, then you need to fill zeros from the left. Usually this one doesn't fill zeros. This one preserves the highest bit. So again it copies the the highest bit to the filled in spaces. So you you get preserved sign for arithmetic operations. OK, again a slight comparison with the with the X86. So if you're using the NOR operation, NA this is basically a not operation because we are using the same 2, the same 2 operands. Here the same register is used as a source, first source and second source. So here this is an equivalent of placing the right value into the EAX and performing not EAX. Yeah, this is how you need to do this in X86 architecture. And shift is pretty much easy because for shift we have extra the same instruction in X86. So we've already seen that memory access. As I told you, the the MIPS architecture is load store architecture, which means for every memory operation we need to place a specific instruction. We have load instructions and store instruction load for taking data from memory into the register store placing something from register into the memory. There are two types, one works with the entire register. So this these two work with words with 32 bit words because we are on the 32 bit architecture. So basically one register is loaded with 32 bit values from memory or vice versa 32 bit values from a register are written somewhere into the memory. This is a bit slightly bit confusing. So what does this mean? is this is used here as a target for the load and here as the source of the of the store. So this is the register which holds the data and the Rs register is used for addressing. So you can use the Rs register, the second or operand and an immediate value. The immediate value is added to the value of this register and then together they are used as a memory address. Why is this so complex? The answer lies here. Let me just scoop back a bit. We have a registers that hold pointers to important areas in your memory. This one is for global data, this one or this one are for local data, for local variables. So if you want to read or write, store or load global or local variable, you will likely use one of these registers as base. But you don't want to read always the first local variable or the 1st global variable. Sometimes you need to read more of them and the compiler has chosen a way how to store them on the stack or how to store them in the global area where all the global variables are. So you know the compiler knows the offset of the variable from the stack pointer or from the global pointer. So basically what you need is that this value, sorry this value here the the register itself. The Rs is usually the global pointer or the stack pointer. And this immediate is a like offset of the variable within the global variables or within the local variables. This is a value which is usually automatically filled in by the compiler because the compiler knows how it stacks the variables in the memory. Similar here with LBNLBULBLBNSB. Sorry, the LBNSB are store and load operations for bytes. Yeah, you can. You can use a more elaborate way how to read a byte, right? You can read 32 bytes, 32 bits, 4 bytes and then use masking and for instance and mask to take only the lower 88 bytes, 8 bits. Sorry to load only single byte, but for some reasons, if you're operating with strings, it might be more useful to load a single byte or store a single byte to and from the memory. The semantics is this is very much the same. The difference is how the byte is treated. So when it's when it's written, it's pretty much simple. Because the store byte takes this register, then crops it takes only the 8 bits, and store only the lower 8 bits somewhere into the memory. That's easy, but what to do in case of loading operations? Because you're loading 8 bits from the memory. But again, these 8 bits needs to be stored in 32 bit register. So we need to extend it like like we did before. So we need to fill it from the left with zeros or with ones or with something. So again, we have two versions of this instruction. The LB is a signed version, so it extends the byte in assigned manner. So it takes the highest bit of the byte and copies it to the to the left, fills the remaining 24 bits using the value of the highest bit. And the LBU is for unsigned bytes. This is what you would usually do with normal characters, because if you have a character like an SK character, it has 8 bits, but it's not assigned value, it's unsigned value, it's from zero to 200-5055. So you usually use this to load a single character from the memory. OK moves are only in between registers. So the move instruction only copies value from 11 register to another register. Unlike in case of XA6 where the move is very very wicked operation that is used for store loads and and moves between registers. And one extra thing, there is ALE instruction. Actually, this is not an instruction. Why LE register an immediate 32 bits, loads this 32 bits, this exact immediate value into this register? Yeah, if I told you this, this is an instruction, a right flag should be risen in your head because this cannot be true, right? Because an instruction has 32 bits in total. So there is no way we can smuggle 32 bit immediate value inside an instruction along with one reference to the register. So we have 16 bits at most. Yeah, this doesn't use an extra register. So we can, we can have 19 bits if you if we really want to, but that's it. We cannot smuggle more than 19 bits into instruction even if we sacrifice the first, the second opera. So how this works actually this is a pseudo instruction. It's like a macro and it's translated into two instructions. The one is called LUI and the second one is or immediate. So what does this mean? LUI is an acronym for LOAD Upper immediate. So it takes 16 bits, but these 16 bits are loaded as upper 16 bits of a register. So let me just visualize this, visualize this. This is a 32 bit register. It has upper 16 bits and lower 16 bits, OK. So normally if you're working with register, loading something into the register, like if you're performing the LB load byte or or LBU, the lower 8 bits are loaded OK. If you're performing the regular load, you load the entire 32 bits. Here the LUI users immediate value, so it can load only 16 bits. So normally you would assume that you are loading the lower 16 bits. But this LUI instruction is special because it loads the upper 16 bits, so it loads this half of the work of the register. OK, why don't we have any other instruction that loads the lower part? Why are we using this operation again? It would be waste of resources. If we have a special load like LBLB I, I would call it load button 16 bits or LLI low lower 16 bits. But that would be a redundant instruction because this part is zeroed when the LUI instruction takes place. So if there are zeros here, we can use or instruction to write anything we want. Because if there is some, some, any values here 01001 etcetera and use use or instead of assignment, it works the same way. Zeros will be merged to zeros, one will override the 0 to one right or operation. So that's why they're using an or instead of assignment just to save instruction. OK, comparison, quick comparison with with X86. Load, store load bytes, load intermediate, whatever you, you, you want. Is basically a morph instruction in X86. Yeah, it's slightly difficult to more difficult to understand because you need to read these brackets correctly everywhere. Every time there are brackets in the morph instruction, it means an address dereference. So in this case we are using the ebx instruction. We are adding something into the the ebx. It's like a base pointer. We are adding an intermediate value to this base pointer. And then these brackets indicate we are using this as a as an address which specified the target place in the memory. So this is a load instruction because on the left is the target, on the right is the source. So the source is in the memory and it's loaded into the EAX register. The same goes for the LV instruction on maps. Vice versa, if you just switch these operations, this is memory address, this is a register. So the value from the register is loaded, it's stored, sorry, it's copied to some place in the memory. OK, let's move on. Yeah, that's the most difficult part of jumps and conditions are usually the most difficult part of any ISA specification. So let me just dig into it slowly. But fortunately for us, jumps on MIPS are not that difficult, where the the foremost and the most simplest is the jump to an specific address. So this is a very easy instruction. Sorry, very easy instruction. Basically add write specific address into the PC counter. That's it. This is an assignment of an of a value into the PC counter. Same goes for jump with register. So the value from a specific register is copied to the PC counter. That's it. rd is jump and link and then that's basically a function call. Jump and link performs 2 operations. First PC counter is stored into the register 31. Remember I told you that before? Just give me a second register 31. By the way, you know the section 31 that that's how they get in the number. So the register 31 is used as a return address. It has a specific meaning. Actually, this is not only part of the ABI, this is also part of the ISA specification, because this specific instruction always works with the register 31. OK, so this register is used as a target for the PC counter. By the way, why? Why is the PC +4? That seems awkward. That seems suspicious. Exactly this. It's not the instruction which performs. The PC holds the address of this gel gel instruction. So we need to return after this jump. If this holds only the PC itself and we then use it as a target to jump back from the from the function call, we will end up on the gel instruction itself which will perform again the call. So we don't want that. So this is the address as you as you adequately put of the next instruction right after this jump. That's where we want to return once we return from the function call, right? And then it again performs the same as the normal jump. It's it's overrides the PC counter and and plays the code pointer somewhere else. Yeah, there is a slight difference here. That's what I want to point out. This jump instruction does not require any additional registers, any additional operands except for this immediate value. So we can use all the part, the whole part that's dedicated both to the registers and to the immediate value, which is 16 bits plus 5 bits plus 5 bits, though 26 bits as an address. That's quite important because this extends the range how far you can jump in your code, 26 bits. How far roughly can we jump in the code? How many kilobytes, megabytes, gigabytes of the code can we jump over off in the memory roughly? Well, if if it were 20 bits, it would be easy. SO20 bits is what for what 20 bits is MLAN. So it's a MB. So the six bits is Nope, 6 bits, sorry, 64. So it's 64 megabytes. So we can jump 64 megabytes ahead in theory. Actually it's assigned no, it's an absolute value. So in theory, we can we can X we can cover the range of 64 megabytes. If we need a larger range, no problem, we have still this. So we can somehow wrestle up any number, any 32 bit number here and then we can jump anywhere we want. But the first 64 bits are somewhat special. megabytes, sorry, are somewhat special because we can cover them using this address. Well, this is an absolute value in this case. In this case, this is an absolute value. You need to use this if you need to cover wider range. What if you needed company with wider like outside of the you can, it's a 32 bit architecture. You cannot address more than 32 bits anyway. So it's it's like the limitation of the architecture. Yeah, it relays. So you can have more than 4 megabytes of virtual memory. That's that's right. Your whole entire application must fit 4 gigabytes. That's it. Hey, I used to work with MS-DOS. kilobytes should be enough for everybody, right? So 4 gigabytes, yeah. If you don't like it, there are 64 bit extensions which use 64 bit registers and then you can cover then you can address 64 bit address. Well, some some, well, maybe not today, but I still lift in time when 32 bit operating system 32 bit windows were quite common and form 4 gigabytes of real physical memory was was a luxury. So it's not that unimaginable. And if you if you need the extension, then you need to extend everything from 6:32 bits to 64 bits and it it will work magically the same way. You just you just extend it. OK, again, quick comparison with X86. Yeah, by the way, normally we are not working with the explicit addresses in our code when when you write assembly language, we use labels. So the label marks specific position in the code and later the compiler will decide where this actually resides in the memory. Actually it's slightly more complicating than that, because sometimes it might be placed in different places in the memory. Your code might be relocated so it it's slightly more complicated. But let's just imagine that somehow compiler decides how to place the right addresses there at at this very moment. OK, so jump to the label is easy because the label is translated to some memory. So jump label means jump specific address that's filled in by compiler. And the same goes for X86, There is no surprise there. And again, for the instruction, the reference for the register, the reference, sorry, there the instructions pretty much the same. You can you say register as the as the address and the only difference is that they use call instead of the the JL they have a specific function call. Actually it this it's much more complex because the call instruction stores the return address to the stack automatically. And the reason this this architecture can do do that is the X86 specifies which register is the stack pointer. So the stack pointer is automatically incremented. The the register is used as a dereference. So it's it's quite more complicated instruction. By the way, this is a trap. It's not entirely true what I said. This is a much more complicated. This is a double in direction. The register ebx holds the address where the pointer is stored. So this will load whatever word is at this address stored in ebx, and then this address loaded from the memory is used as the address where we should jump double indirection. Yeah, I know. If you didn't catch that, never mind. It's just just remember it's more complicated on X-80 or this. This example is more complicated than than this one. This is straightforward. The address from the register is used as the target where we are jumping. OK, jumps are easy. Let's go easier. Let's go to conditional jumps. Conditional jumps require some form of testing, so we need something to compare before we jump. In the MIPS instruction set there is A. There are two jumps actually to distinguish themselves from the jump instructions, which are like a straightforward we are always jumping. They are called branches because they are conditional. Sometimes we take the branch, sometimes we take the other branch. So they start with B not with J. And beq is a current name for branch if equal. So if the two registers, sorry, if the yeah, if these two registers I'm placing there are equal hold the same value, then I'm performing the jump. If not, I'm merely following within with another instruction. So if the equality holds, then the PC, the the program counter is overridden with this address. If it doesn't hold, we just increment the program counter, just following up with the next instruction. Analogically for BNE, the NE holds for not equal. So this is like opposite. This is the negative of this instruction. Yeah, I, I several times I prize myself with pointing out the fact that they're trying to save the instructions and suddenly they have two almost identical instructions for performing branches, right. Yeah, there is a reason for that. Very often you are comparing something with 0 and very often you need to jump if it's zero and very often you need to jump when it's not zero. And the zero is easy because 0 is already there. It's in the zero register register. It's the first register, right? So one of these two items is very often the zero register. But it will be difficult to have another register with non 0 value. So it's easier to have two instructions 1 when you use if you want to branch if something is 0 and the other one if, if it's not 0, that's that's the, that's the logic, that's the idea behind this. And for testing, for inequality testing, we have a special instructions SLT SLTU that depends on whether we are comparing unsigned or signed signed versions. And you get. It's slightly more complicated because you get the destination register where the result of the comparison is stored. So you're performing lesser than. The SLT hold stands for lesser than. holds a boolean value of this comparison between Rs and RT. So if Rs is lower than RT, then Rd. will get one true. If this doesn't hold, it will get a zero false. OK, this is basically and you can rewrite this in AC because if you have like A, if A is lesser than B, you can extract the condition and you can have something like You can do that in C as well. You can take out the. You don't have to mangle comparisons with if statements or any other statement. You can extract the logical operator, the comparison operator, and store the result here. So technically that's what happening here. You first perform this comparison, store the result into the register, and then later you use these two to put this result equal or not equal to 0, right? So if you want to perform this type of if it breaks down into two instruction, 1 instruction performs the comparison itself and the second instruction perform the jump if the comparison was successful or not. There are some slight details like whether we are working with onsite or unsigned, whether we are working with two registers or a register or an immediate value. But it's just a variation on the theme. By the way, we don't have greater than, we have only smaller than. Is that bad? Yeah, we can swap and that's right, it's easier just mind teaser. So if we if you want greater than then you just swap these two and that's it. What if we need greater or equal or lesser or equal in this manner? Well, yeah, 111.11 option would be to use two instructions, but that's a bit impractical. Any other and same? OK, not really. And this comes free, Why you just switch from this one to this or vice versa? OK, so you just need to hold all the details in your mind because if you're writing this manually, it might be a bit tricky not to get lost in the negations and which which one of these you want to use. But in the end it it's not that not that difficult. You just need to use appropriate combination, proper order of these two and proper selection of these two and you will get you, you can get all the types of inequality comparisons you can imagine. OK, yeah, X86 goes around this in a very different way, by the way. By the way, just a small teaser. Could you imagine how to implement this? Could you, could you do that still if I give, if I take these instructions away from you? So we still need to perform lesser than, greater than, but I can I tell you that you don't need these instructions to do that. What instructions which you already have, which you already know, can you use as a supplement, as a, as a, let's say, replacement if somebody orders you, you know, Trump gives you a new order, new law that you cannot use SLT and SLTU instructions. So what shall we do with that? Yeah, we can move to Canada, but that's that's that might be more practical. That's right. But just imagine for a short while that you can't move value, then you can like order the check to be or you can use and to clear out everything except the design bit. And then that's right, That's right, you're on the right track. So you can use subtraction. And basically this comparison underneath perform subtraction because if you subtract these two values, then you will end up with a 0 or positive value if this one is lower than, sorry if this one was greater than this one. Or vice versa, you will end up with a negative value if this one is smaller than this one, right? If you just put minus in between them instead of comparison, right? And we already know that in to complement, we can just take a peek at the highest bit. That's probably what you meant by the ends. And so basically, we don't have to use the ends, We can just shift the number 31 positions to the right, which will clear the upper 31 bits and only the upper bit will remain on the right. So basically, if we just replace it with one subtraction and one shift to the right, we will get the same result. And that's probably what's happening underneath in the hardware, maybe in slightly more optimized way, but basically that's it. The same goes here. The BQ is basically a comparison between these two and then jump Z. By the way, this is the CMP instruction is a special version of sub instruction. That's why I was was teasing you with this, this small mind teaser with the replacement of the lesser than with the subtraction. Because CMP is basically a subtraction that doesn't store the the result. It only alters the flags. In X86 the result of the comparison is stored in flags. I will get to that in short order. And the jumps are reading the flags and jumping based on some certain conditions expressed in the flag register. So the CMP is subtraction without the store. So it it likes perform EAX minus EBX, but it doesn't store the result, it doesn't overwrite the EAX, it's just store the the flags. By the way, subtraction alters the flags in the same way, it just writes the the result here. And the Jay-Z says jump IF0. Why jump if zero? That sounds awkward. I'm just waiting if every all the pieces I just told you just kind of fit together and fall into the right image in your mind. It's telling me that there's return to 0 if they are No, no, no, no. Actually no. This is this is a subtraction. It just doesn't store the value into EAX, but it alters all the registers in the same manner a sub instruction would. So like the indications of the result of the sub instructions are somehow stored in the registers. And this is jumping if the previous result was 0. So when the result is 0. It's zero when they're equal. It's zero when they're equal because if you take a value and subtract the same value then you will get the zero. If they're different, you won't get the zero. So basically that's it. The JZ is the same as equality because this is a subtraction and if these two numbers were the same, the result would have been zero. It's not stored in the EAX because this is compare instruction, but it's indicated in the flags. There is a 0 flag actually, so it will be stored there and this jump will just read the flag and say hey the flag is set, I'm jumping or if it's. If they are not equal the flag wouldn't be set and this jump wouldn't take place OK. So this is the equivalent of beq branch if equal. OK, for inequality comparisons you need to use SLT and then branch if equal or branch if not equal. So this is just the hey, you can do this for your home assignments. Again, you perform the same comparison here but you change the type of of jump and this is jump if lower. So again, it takes a look at the register the right flags and if the flags indicated that the result of this subtraction was less than 0 in the end, then it performs the jump. The same goes here, OK. And you have a whole set of these instructions JLJLEJGJGE which is a combination of lower than lower equal, greater than greater equal. And it all takes the the notions from the flags. Always you are using the same compare instructions before. OK, finally let us go through a few easy, maybe not completely easy, but not that complicated or the complex examples. The first one is how this for loop would be probably unoptimized in an unoptimized way translated into the instructions. So it's a very simple loop. We just have the EI, sorry, I variable, which is the local variable. Probably this one will be optimized so it will be stored in a register because we don't need to store it somewhere in the memory. The N is like the size of the array. It's a probably global variable. And a is the pointer to the beginning of the array because we are in C so this is a pointer to the beginning of the variable. And again, I'm assuming, yeah, that there are global variables. And what we are doing is that we are filling this variable with a particular constant like 42, which is a very important number, as you already know. So we are filling the number, we're filling the array with the initial value. OK, easy enough. So what we are doing here, first step Eddy, we are storing T0. We we need to sorry to the T0 which is like a temporal register. We are storing the address of a. Who the hell told me that that the array a the actually the pointer not the array itself is at value 28. How did I get to that? I, I wouldn't know that actually I took this, took this code for granted from I just wrote a much more complex code. Well, not that much complex, but the code was slightly larger because there was the main function and the declaration of global variables, etcetera, etcetera. And for some reason compiler decided that this this would be a good spot for the variable a. So it place it there and I cannot do any heck with it. It's just compiler decision. So I'm just giving you the output of the compiler. Compiler says it will be here. So it's it's there. That's it. OK then I'm loading the word where the NSN is and again N is the value 4. This is just a strange notation. This 4 for some reason is written in front of the GP register. It's like we are using the 4th offset of the global variables. GP is the global pointer. So this is the just GP plus 4 which is used as the address and that's loaded to T1. Finally we are moving the 0 value. Hey, the zero register becomes useful again. So we are moving the 0 value value to the T2 that that's a much quicker initialization than if you just had to perform something else. By by the way, do you know how to 0 a register quickly? If we wouldn't have the zero register, how to place a 0 into another register like T2 quickly without using the zero register? Yes, we can use end end with zero and we we have end I which uses immediate value 0. So yeah, one one option would be to end 0 to the register that will clean it up. That's right. Any other options? Not not Yeah, we can do lots of things with with zero. That's that's right. Well, not, not or one wouldn't work because that's you're you're not or you are oring 0, which doesn't change the number and then negation would flip it so it wouldn't zero it. So this one wouldn't work. But I I heard something else bit shifting. Yeah, we can shift it 32 bits to the right, which pretty much clears it that that's right. Any other option. And that's good because you're thinking like real assembly programmers. Now, one final one. It's just one which is my favorite because it was used back in my days when I was learning assembly language. That's right, saw it with with itself or this was like one of the my most favorite instructions back in my days because this was the this was the fastest way how you can 0A register or it was at least on X86 architecture because it's much, much shorter than writing than moving a 0 into EAX because the zero would have to be written as an immediate value in the code. This is this takes only two bytes. OK, so we are initializing TT 2. So basically from now on in T2 we have the I variable, so I is aliased in our minds to T2 and TT3 will for our purposes hold the immediate value here, which is the constant we are using to fill the array. Yeah, it's a good idea usually to place this value somewhere into the registers because it's much faster to use register for many operations than to use it for other things. OK, so we are using the 0 and 42 to get odd together and written to a register again. Or I is one of the fastest way how to initialize the lower 16 bit of some some other register. Actually all the all the registers because the whole register T3 will be zeroed except for the lower 16 bits which are the result of this or operation. And finally this this, this is where it gets more interesting. This is just an initialization. We are jumping to the condition. For some reasons, the compiler decided to place the condition, the condition which is tested at the beginning of each loop, at the end. Yeah, that's compiler's paragraph, right? So before we start, we jump here and here there is a comparison. The SLT will compare I and N Remember I is in T2 and N is in T1. So we are comparing T1 and T2. SLT is lesser than. So just imagine lesser than between these two. This is exact copy of this because this is an and this is I, right? And the result of this comparison will be in a temporary T4. So in the end we are comparing T4 with 0. Again, zero becomes very useful. And if this holds, we are jumping to the body, to the body of the loop actually. And if it doesn't hold, we are continuing over here. And that's basically where the end, where is the end of the loop. So if if this doesn't hold, we are merely continuing on our way, not executing the body itself. OK, And the body itself holds these values. First of all, we need to multiply I with four. So what does this hold? Why, why, why there's no multiplication? What is SSLL shift left? Yeah, because multiplication by 4 is actually shift to the left by two, right? Because this is 2 to the power of 2 is 4. So shift to the left by two is the same as multiplied by four. And since this is a fixed constant, it's pretty much easier to do it by shift. Actually there is a multiplication instruction. I haven't told you about it because it's much more complex, because the result of of the multiplication needs to be stored in two registers. So it's pretty pretty tricky. But for this purpose, shift is much more better. And then we need to add the offset of I * 4, which we just computed to the a base. Because this actually needs to be resolved in the manner of pointer arithmetics, right? Pointer arithmetics dictate that assuming this is the array of integers and integer holds 32 bits. So this This is why we get 4 here. So we need to add the offset of I to the base pointer A to get the proper address of the proper spot to which we are writing right now. This is where this addition comes. Store word uses the previously computed address T4. So this is the temporary variable which holds the actual address of the actual item in the array which we are writing right now. So the store word will use this address and a zero offset because we are really want to put store to this address and the T3 holds our 42 variable the constant right? So we are storing T3 into this address. And finally we need to perform the last piece of the iteration, which is this increment. And that's pretty easy. This is just an addition, right? So yeah, now I dissect it line by line, this code. Are there any questions regarding this this instruction? Give it a decade or two, you know, it's not that complex. You just need to read a few few a few programs and then you will get hang of it. Probably not when I'm reading it, I still need to read it line by line. It's not that I'm just taking a glimpse at it and I immediately tell you, oh, it's this for loop. No, I I also need to examine it closely because no human possibly, or maybe there are some humans, but regular programmers don't read assembly fluently. So don't don't feel bad that you're don't reading this fluently, but you, well, it's, it's a slow work. You need to think about it a lot. And it's much slower than if you're writing in AC for instance. But that's why they invented C and and high languages, because nobody wants to write an assembly. Actually, normally you need to write an assembly only if you're doing something very low level, like writing specific drivers for specific devices or writing some very tiny pieces in in a OS kernel. But normally you don't have to write assembly nowadays. OK, another example. Much more simple. Simpler, but much more tedious. Much more tricky. Sorry, but maybe tedious for some. This is a simple expression. N multiplies by 5 + 3. Nothing fancy there. So what we need to do is fetch N because this is probably some global variable. Again, we are using GP and this is a constant generated by compiler which just happened to place this variable on the offset 4. We don't know why. So we store it to T0. We store 5 to T1, so we get 5 ready in a register so we can use it, use it easily for operations. And then there is this multiplication instruction I told you about, but I didn't explain in detail. So just at this moment, it's actually a bit fake. It's simplified. It's not really exactly how it's written in MIPS, but just bear with me. So we multiply T1 with T0 and store it into T0. OK, pretty much easy. That's why there's the fake means this is not an actual instruction. It's, it's more complicated, but just let's let's assume this works. It's, it should work if, if we don't don't need to store the upper 32 bits. And finally we need to perform add, add operation to T0 the three and that's it. And we store the result into the I variable, which is for instance, in the 0 offset of the GP. Easy enough. But I can tell you this could be also a code generated by the compiler for this, for this particular expression. So what we are doing here where we fetch the end in the same way? Yeah, that's pretty much obvious. Then we multiplied by 4. Because shift to the left is much faster, much easier, much, much simpler to handle then multiplication. Imagine that this is a very complex, very heavy operation for the, for the CPU. It might not even take a single, a single cycle, it might take multiple cycles. So it's like a, it's stalling the pipeline. It's it's very heavy. Shift to the left is very simple. It's it's easier than. Then we add N to the previous result. So if we multiply N by 4 and then add one additional N, it's the same as if we multiply the N by 5, right? Yeah, that's a trick the compiler is using all the time because it takes the advantage of the fact that the five is here as a constant. So if it's a constant, then the compiler can dissect it in many ways. And this is one of the tricks that the compiler can do to optimize the code. So we completely avoided the multiplication, right? And basically we are using the same amount of instructions as here, except we have avoided the costly multiplication, right? So imagine that you already took notion of that. Here we are not multiplying by 4 here we are using shifts whenever we can. The compiler is actually doing that. OK, so that was another example. Few more things before we wrap up. First one, I told you several times about the flags register when we was talking about comparison. So let me just give you a glimpse at the register. This is how the register looks at X86. The orange flags are the arithmetic flags. So these are the flags adjusted, modified by every arithmetic operation. And basically what every arithmetic instruction does is it fills these these registers based on what was the result of the operation. So if we're performing sub comparison is the same as if we're comparing subtraction. As I already mentioned, the most important flags are zero flags, Z flag. Over here it's set only when the result is 0. It's good to know if it's 0 a sign flag as as here is basically the copy of the highest flag of the result. If it's signed operation OK, because if it's if the highest bid is 1, then the sign flag is one because the result was negative otherwise it's zero, which means it's positive carry flag. That's one of the most important ones actually. Is a flag which is set if the operation has one extra bit that needs to be, you know, transferred into high order. For instance, if you're adding two numbers and the result overflows, then the extra bit goes to the carry flag. Also, if you're shifting to the left, the lowest shifted bit is stored into the carry flag. Actually it's not entirely true. It's it's true only for rotating operations I think, which are similar to shifts, but it's not that important. An overflow flag is set when the operation overflows. So it's similar to carry, but the the overflow is more general. The carry can still hold 0 because the operation might overflow much more than 2210 above the the width of the register. OK, so these are the flags few more things about Isas. The instruction set architecture can be designed in many, many ways. There used to be some classification about types of these Isas. Namely you probably heard about the acronyms TISK and RISK. This one stalls stands for the Complex Instruction set computer and the one. The other one is for the reduced set instruction set. Nowadays RISK and CISQ is somewhat losing their meaning because in the past when I was studying these subjects, there was there were CPUs like ARM, for instance, or Motorola or maybe even MIPS, which would be denoted risk because they have quite small instruction set and they're aiming at being very, very performant. So they they're trying to decode the instructions very fast. They're trying to do the best they can to process the reduced set they're actually can process. And the complex instruction set was using this specific notion that it's a good idea to give a broad variety of different instructions and instructions, versions and types and variations to the programmer because the programmer would could use the specific instruction for a specific problem, right? Actually this is no longer true because as I just mentioned a few moments before, we are not using assembly language to write software anymore, only in a very very specific occasions. Normally the compiler generates the assembly code, so why bother if the difficult part is done in the compiler? We don't need very complex sets of instructions to accommodate needy users, needy programmers. The compiler can do that. So nowadays we are focusing more on narrow subsets of of instructions and even the architectures which were like. Mentals or or examples of tisk approach like X86 architecture is nowadays reducing the number of instructions it directly support. I will show you that on a few slides later. So they are supporting massively a very small subset of instructions that should be used regularly. And yeah, they are usually supporting the other instructions for for compatibility reasons, but they usually execute these other instructions in a very slower manner. So it's a good idea to use only a subset of this Tisk instruction set. By the way, there are also other different approaches to that. One of them is a very long instruction word approach which tries to avoid the decoding of the instruction by writing all the important stuff like which units should be initiated, which code should be, which pieces of hardware should be initialized in which order into a very long bitwise word. Let me scroll very quickly to give you an example of what I mean. Last week I showed you this example. And in this example, this instruction is decoded into a sequence of internal micro instructions or internal steps if you will. And this is basically a specific list of operations that needs to take place. And I can encode this in a very long bit, twice in a very long bit word where the individual gates will have their individual bit sets when they need to open or something like that. Yeah, I'm, I'm far fetching this. It's not that simple as I'm putting it, but just to give you a glimpse how this might work. So I can give you an instruction which is like a partially or totally decoded and written in a very long bit vector. And this is what these types of architectures aim to do. However, it's turned out not to be very practical. The decoding can be done quite easily even for complex architectures, at least nowadays when we have enough silicone, enough circuitry on the wafer, so it's no longer a very viable option. It was still used for specific architectures, like I think it was in AM DGPU still 2010 or something like that. Then they switched to CGN architecture and they they stopped using this particle approach. Slightly better way how to do this was the Epic. This has nothing to do with rare or legendary, this is just an acronym. This is like explicitly parallel instruction computer, which means they try to bundle multiple instructions into one instruction word or instruction set. This is what for instance, IIA 64 which I which I told you about when I was talking about registers is doing and they basically place multiple instructions in what's called instruction bundle. And these instructions are designed so that they can be executed concurrently in parallel. So compiler is helping the CPU with concurrent execution of instructions whenever possible. Another important aspect which we are examining when talking about ISS is orthogonality, whether a specific register can be used in specific operations. If they are completely orthogonal, then any register can be used for any operation. So if you have an addition, multiplication, storing some pointers, whatever, you can use whatever register you would like. MIPS 32 is almost orthogonal or terrible word. Sorry, my tongue is on vacation today. So it's almost orthogonal, not entirely because you have the zero register which is special, and you have the 30 ones register where the address is stored for the jumps for the calls. So it's not entirely but almost on the other way. On the other hand, X86 is almost not orthogonal because there are so many instructions where only specific one register or specific set of registers can be used. And finally, I told about this several, I mentioned this several times load, execute, store. So whether we are using load and store approach to load the data and store the data or we are using a more straightforward approach like morph instructions which or other instructions that directly address the memory, OK. And before we conclude bad timing, OK, I would need few more minutes than 5 and I have only 5 minutes till the end. So I just started and I will need to retake this topic at the end of the at the beginning of the next weeks. What can what can you? So at the end I would like to give you a few glimpses, few notions, few hints about how this is implemented in hardware. Actually, we are not talking about this in detail. If you want to know this in detail, you need to pick another school, because we are not doing hardware things on that level here. We are more software oriented. But it's a good idea to know a few things about how it really works, or at least how it appears it works in the real hardware, because then you can optimize for it. Then you can design better software for for the particular CPU or for in general for for all the CPUs. So basically we need to know how the memory is organized. There are usually some set of. There are sets of caches that pre phase the memory so that you can you can store. The hardware automatically stores data there so you don't have to waste time waiting for the data to get from the main memory. Or when you're storing the data, they can be cached in the caches so they then don't have to be written back to the main memory if you use the data frequently enough. CPU cores have their own registers, and actually, yeah, this is specified by ISA. But the important thing is this doesn't have to match with the physical registers. For instance, X86 architecture performs something which is called register remapping. You still have the registers in your code named EAX and EB etcetera, but in physical world you have like 100, sixty, 180. I'm not entirely sure about the number registers on the CPU available and there are. There is extra circuitry that renames the register that maps the physical registers to the virtual registers which are named in the ISA. So your code can run differently, meaning your data, when they are stored in a specific register like EAX, can be stored in a different physical register. If the hardware decides to do that, your code wouldn't know that because your code would appear as if it's still the EAX register for you, but for the hardware it will use a different register. Why they are doing that? Because we have so few registers and sometimes it's better for performance if you can store the data in one register and then use another register as an alias for different instruction. So you can run these instructions in parallel for instance. And finally there are technologies like hyper threading which actually creates virtual cores. So according to ISA, you, you have a say, virtual view of the CPU that it has several cores, but in fact, some of these cores are merged together and using the using the execution units share the execution units. OK, I think this is a good place where, where we can stop for, for now, because this is a picture I will remember for the next time. So before we conclude, I think we have like a one minute left. Are there any questions regarding the instruction sets or anything? We we were covered this, this week, this this lesson, No questions so far. OK, so next week we'll finish the we will finish the CPUs. It's just only a few slides left and we start a new topic. So thank you for your attention and see you next week hopefully.